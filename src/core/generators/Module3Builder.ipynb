{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d11670a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module 3 Master Notebook created at: module3_master/Module_03_Master.ipynb\n"
     ]
    }
   ],
   "source": [
    "# === Builder 1: Initialize Module 3 Master Notebook ===\n",
    "# Creates module3_master/Module_03_Master.ipynb with title, overview, imports, and dataset load.\n",
    "\n",
    "import os, nbformat as nbf\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Create folder for module 3\n",
    "# -----------------------------\n",
    "OUT_DIR = \"module3_master\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"Module_03_Master.ipynb\")\n",
    "\n",
    "def md(txt): \n",
    "    return nbf.v4.new_markdown_cell(txt)\n",
    "\n",
    "def code(txt):\n",
    "    return nbf.v4.new_code_cell(txt)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Create an empty notebook\n",
    "# -----------------------------\n",
    "nb = nbf.v4.new_notebook()\n",
    "cells = []\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Title & Overview\n",
    "# -----------------------------\n",
    "cells += [\n",
    "    md(\"\"\"# üìò Module 3 ‚Äî Classification\n",
    "\n",
    "## Logistic Regression ‚Ä¢ Decision Trees ‚Ä¢ Ensembles ‚Ä¢ ROC/AUC ‚Ä¢ Thresholding ‚Ä¢ Model Tuning\n",
    "\n",
    "This module introduces **classification**, one of the core techniques in supervised learning.\n",
    "\n",
    "We will cover:\n",
    "1. Binary vs. multiclass classification  \n",
    "2. Logistic Regression  \n",
    "3. Decision Trees  \n",
    "4. Ensemble Methods (Random Forest & Boosting)  \n",
    "5. Classification Metrics (Confusion Matrix, ROC, Precision‚ÄìRecall, F1)  \n",
    "6. Model Tuning & Validation  \n",
    "7. Hands-On Exercises (Heart Disease, Spam, Wine)\n",
    "\n",
    "Throughout the module, we will use synthetic datasets from `datasets_module3.py`,\n",
    "with a consistent random seed (1955) to ensure reproducible examples.\n",
    "\"\"\")\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Imports + dataset import\n",
    "# -----------------------------\n",
    "cells += [\n",
    "    code(\"\"\"# --- Imports for Module 3 ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, validation_curve\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Dataset helper functions\n",
    "from datasets_module3 import make_heart_disease_synth\n",
    "\n",
    "# Consistent seed\n",
    "SEED = 1955\n",
    "\"\"\")\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Load Heart Disease dataset\n",
    "# -----------------------------\n",
    "cells += [\n",
    "    md(\"## 3.0 ‚Äî Load Dataset (Heart Disease)\\nWe will use this dataset across Sections 3.2‚Äì3.6.\"),\n",
    "    code(\"\"\"# Load synthetic heart disease dataset\n",
    "df = make_heart_disease_synth(n=600, seed=SEED)\n",
    "\n",
    "# Preview the dataset\n",
    "df.head()\"\"\")\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Section Placeholders\n",
    "# -----------------------------\n",
    "cells += [\n",
    "    md(\"\"\"---\n",
    "\n",
    "# 3.1 ‚Äî Introduction to Classification  \n",
    "*Visual intuition for binary vs. nonlinear boundaries*  \n",
    "*(builder 2 will populate this section)*  \n",
    "---\n",
    "\n",
    "# 3.2 ‚Äî Logistic Regression  \n",
    "*(builder 3 will populate this section)*  \n",
    "---\n",
    "\n",
    "# 3.3 ‚Äî Decision Trees  \n",
    "*(builder 4 will populate this section)*  \n",
    "---\n",
    "\n",
    "# 3.4 ‚Äî Ensemble Methods (Random Forest & Boosting)  \n",
    "*(builder 5 will populate this section)*  \n",
    "---\n",
    "\n",
    "# 3.5 ‚Äî Classification Metrics (Confusion Matrix, ROC, PR Curve)  \n",
    "*(builder 6 will populate this section)*  \n",
    "---\n",
    "\n",
    "# 3.6 ‚Äî Model Tuning & Validation  \n",
    "*(builder 7 will populate this section)*  \n",
    "---\n",
    "\"\"\")\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Save notebook\n",
    "# -----------------------------\n",
    "nb['cells'] = cells\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(nbf.writes(nb))\n",
    "\n",
    "print(f\"Module 3 Master Notebook created at: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5006f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Builder 2 applied ‚Äî Section 3.1 added to Module_03_Master.\n"
     ]
    }
   ],
   "source": [
    "# === Builder 2: Append Section 3.1 to Module_03_Master.ipynb ===\n",
    "# Adds visual demo for classification decision boundaries.\n",
    "\n",
    "import os, nbformat as nbf\n",
    "\n",
    "OUT_DIR = \"module3_master\"\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"Module_03_Master.ipynb\")\n",
    "\n",
    "nb = nbf.read(open(OUT_PATH, \"r\", encoding=\"utf-8\"), as_version=4)\n",
    "\n",
    "def md(txt): \n",
    "    return nbf.v4.new_markdown_cell(txt)\n",
    "\n",
    "def code(txt): \n",
    "    return nbf.v4.new_code_cell(txt)\n",
    "\n",
    "cells = []\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Section Header\n",
    "# ---------------------------------------------------------\n",
    "cells += [\n",
    "    md(\"\"\"# 3.1 ‚Äî Introduction to Classification\n",
    "\n",
    "In this section, we build intuition about **binary classification** by visualizing \n",
    "decision boundaries for two simple models:\n",
    "\n",
    "- Logistic Regression (linear boundary)  \n",
    "- Decision Tree (nonlinear boundary)\n",
    "\n",
    "We use a toy dataset (`make_moons`) to clearly show the difference between linear and nonlinear classifiers.\n",
    "\"\"\")\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Code: Decision Boundary Demo\n",
    "# ---------------------------------------------------------\n",
    "cells += [\n",
    "    code(\"\"\"# --- 3.1 Decision Boundary Visualization ---\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic 2D dataset for visualization\n",
    "X_moons, y_moons = make_moons(n_samples=400, noise=0.25, random_state=1955)\n",
    "\n",
    "# Split for training/testing (not strictly necessary here, but consistent with workflow)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr_m, X_te_m, y_tr_m, y_te_m = train_test_split(\n",
    "    X_moons, y_moons, test_size=0.3, random_state=1955\n",
    ")\n",
    "\n",
    "# Train classifiers\n",
    "log_clf = LogisticRegression().fit(X_tr_m, y_tr_m)\n",
    "tree_clf = DecisionTreeClassifier(max_depth=4, random_state=1955).fit(X_tr_m, y_tr_m)\n",
    "\n",
    "# Helper function to plot decision boundaries\n",
    "def plot_decision_boundary(model, X, y, title):\n",
    "    x_min, x_max = X[:,0].min() - 0.5, X[:,0].max() + 0.5\n",
    "    y_min, y_max = X[:,1].min() - 0.5, X[:,1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(x_min, x_max, 300),\n",
    "        np.linspace(y_min, y_max, 300)\n",
    "    )\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    cmap_bg = ListedColormap([\"#F6C4C4\", \"#C4E4F6\"])\n",
    "    cmap_pts = ListedColormap([\"#E53935\", \"#1E88E5\"])\n",
    "\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.contourf(xx, yy, Z, cmap=cmap_bg, alpha=0.7)\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap=cmap_pts, edgecolor=\"k\", s=20)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot logistic regression decision boundary\n",
    "plot_decision_boundary(log_clf, X_moons, y_moons,\n",
    "    \"Logistic Regression ‚Äî Linear Decision Boundary\")\n",
    "\n",
    "# Plot decision tree decision boundary\n",
    "plot_decision_boundary(tree_clf, X_moons, y_moons,\n",
    "    \"Decision Tree (depth=4) ‚Äî Nonlinear Decision Boundary\")\n",
    "\"\"\")\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Append to notebook\n",
    "# ---------------------------------------------------------\n",
    "nb.cells.extend(cells)\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(nbf.writes(nb))\n",
    "\n",
    "print(\"Builder 2 applied ‚Äî Section 3.1 added to Module_03_Master.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47394b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Builder 3 applied ‚Äî Section 3.2 Logistic Regression added to Module_03_Master.\n"
     ]
    }
   ],
   "source": [
    "# === Builder 3: Append Section 3.2 ‚Äî Logistic Regression ===\n",
    "\n",
    "import os, nbformat as nbf\n",
    "\n",
    "OUT_DIR = \"module3_master\"\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"Module_03_Master.ipynb\")\n",
    "\n",
    "nb = nbf.read(open(OUT_PATH, \"r\", encoding=\"utf-8\"), as_version=4)\n",
    "\n",
    "def md(txt): \n",
    "    return nbf.v4.new_markdown_cell(txt)\n",
    "\n",
    "def code(txt): \n",
    "    return nbf.v4.new_code_cell(txt)\n",
    "\n",
    "cells = []\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Markdown header for Section 3.2\n",
    "# ---------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "# 3.2 ‚Äî Logistic Regression (Heart Disease)\n",
    "\n",
    "In this section, we fit a **logistic regression classifier** to the heart disease dataset.\n",
    "We will:\n",
    "\n",
    "- Clean & prepare the dataset  \n",
    "- Build a preprocessing pipeline  \n",
    "- Train a logistic regression model  \n",
    "- Extract and interpret coefficients  \n",
    "- Use predicted probabilities  \n",
    "- Explore threshold tuning  \n",
    "- Evaluate using a confusion matrix and classification metrics  \n",
    "\n",
    "This mirrors the process from Module 2 (OLS) but adapted for classification.\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Code: Preprocess + Train Logistic Regression\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- 3.2 Logistic Regression Pipeline ---\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('disease', axis=1)\n",
    "y = df['disease']\n",
    "\n",
    "# Identify numeric & categorical columns\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline:\n",
    "# - numeric: median impute + standardization\n",
    "# - categorical: most-frequent impute + one-hot encoding\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', num_pipe, num_cols),\n",
    "    ('cat', cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "# Create train/test split\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.20, random_state=1955)\n",
    "\n",
    "# Logistic Regression pipeline\n",
    "log_reg = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('model', LogisticRegression(max_iter=500, random_state=1955))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "log_reg.fit(Xtr, ytr)\n",
    "\n",
    "# Predict class labels and probabilities\n",
    "yhat = log_reg.predict(Xte)\n",
    "yprob = log_reg.predict_proba(Xte)[:, 1]\n",
    "\n",
    "# Display first few predictions\n",
    "yprob[:10]\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Extract Coefficients\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- Extract Logistic Regression Coefficients ---\n",
    "\n",
    "# Get underlying model\n",
    "lr_model = log_reg.named_steps['model']\n",
    "\n",
    "# Get one-hot-encoded categorical names\n",
    "cat_features = log_reg.named_steps['pre'].named_transformers_['cat'] \\\n",
    "    .named_steps['onehot'].get_feature_names_out(cat_cols)\n",
    "\n",
    "# Combined feature names after preprocessing\n",
    "feature_names = np.concatenate([num_cols, cat_features])\n",
    "\n",
    "coef_table = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": lr_model.coef_.flatten()\n",
    "}).sort_values(\"Coefficient\", ascending=False)\n",
    "\n",
    "coef_table\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Threshold tuning\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- Threshold Tuning Demo ---\n",
    "\n",
    "thresholds = [0.3, 0.5, 0.7]\n",
    "\n",
    "for t in thresholds:\n",
    "    preds_t = (yprob >= t).astype(int)\n",
    "    prec = precision_score(yte, preds_t)\n",
    "    rec  = recall_score(yte, preds_t)\n",
    "    print(f\"Threshold={t:.2f} ‚Üí Precision={prec:.3f}, Recall={rec:.3f}\")\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Confusion Matrix + Metrics\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- Classification Metrics ---\n",
    "\n",
    "cm = confusion_matrix(yte, yhat)\n",
    "\n",
    "acc = accuracy_score(yte, yhat)\n",
    "prec = precision_score(yte, yhat)\n",
    "rec = recall_score(yte, yhat)\n",
    "f1 = f1_score(yte, yhat)\n",
    "auc = roc_auc_score(yte, yprob)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", auc)\n",
    "\n",
    "# Display confusion matrix\n",
    "cm\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Markdown: Placeholder for later interpretation\n",
    "# ---------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "### ‚úçÔ∏è Interpretation Notes (to be completed after running the section)\n",
    "\n",
    "- Discuss which features have the strongest positive/negative coefficients  \n",
    "- Explain probability outputs and what a 0.7 threshold means  \n",
    "- Compare precision/recall trade-offs  \n",
    "- Interpret the confusion matrix  \n",
    "- Explain ROC AUC in plain English  \n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Append Builder 3\n",
    "# ---------------------------------------------------------\n",
    "nb.cells.extend(cells)\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(nbf.writes(nb))\n",
    "\n",
    "print(\"Builder 3 applied ‚Äî Section 3.2 Logistic Regression added to Module_03_Master.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e7b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Builder 4 applied ‚Äî Section 3.3 Decision Trees added to Module_03_Master.\n"
     ]
    }
   ],
   "source": [
    "# === Builder 4: Append Section 3.3 ‚Äî Decision Trees ===\n",
    "\n",
    "import os, nbformat as nbf\n",
    "\n",
    "OUT_DIR = \"module3_master\"\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"Module_03_Master.ipynb\")\n",
    "\n",
    "nb = nbf.read(open(OUT_PATH, \"r\", encoding=\"utf-8\"), as_version=4)\n",
    "\n",
    "def md(txt):\n",
    "    return nbf.v4.new_markdown_cell(txt)\n",
    "\n",
    "def code(txt):\n",
    "    return nbf.v4.new_code_cell(txt)\n",
    "\n",
    "cells = []\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Section Header\n",
    "# ---------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "# 3.3 ‚Äî Decision Trees (Heart Disease)\n",
    "\n",
    "In this section, we fit a **decision tree classifier** to the heart disease dataset.\n",
    "We will:\n",
    "\n",
    "- Use the same preprocessing pipeline as logistic regression  \n",
    "- Fit a decision tree  \n",
    "- Visualize the tree structure  \n",
    "- Interpret decision paths  \n",
    "- Compare training vs test accuracy  \n",
    "- Explore model complexity (max_depth)  \n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Fit Decision Tree Classifier\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- 3.3 Decision Tree Classifier ---\n",
    "\n",
    "# Reuse preprocessing from logistic regression section\n",
    "# (num_cols, cat_cols, pre, Xtr, Xte, ytr, yte already defined)\n",
    "\n",
    "tree = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('model', DecisionTreeClassifier(max_depth=4, random_state=1955))\n",
    "])\n",
    "\n",
    "tree.fit(Xtr, ytr)\n",
    "\n",
    "# Predictions\n",
    "yhat_tree = tree.predict(Xte)\n",
    "\n",
    "# Performance metrics\n",
    "acc = accuracy_score(yte, yhat_tree)\n",
    "prec = precision_score(yte, yhat_tree)\n",
    "rec = recall_score(yte, yhat_tree)\n",
    "f1 = f1_score(yte, yhat_tree)\n",
    "\n",
    "print(\"Decision Tree Metrics (depth=4)\")\n",
    "print(\"Accuracy :\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall   :\", rec)\n",
    "print(\"F1 Score :\", f1)\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Visualization of the Tree\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- Visualize the Decision Tree ---\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plot_tree(\n",
    "    tree.named_steps['model'],\n",
    "    feature_names=num_cols + list(\n",
    "        tree.named_steps['pre']\n",
    "        .named_transformers_['cat']\n",
    "        .named_steps['onehot']\n",
    "        .get_feature_names_out(cat_cols)\n",
    "    ),\n",
    "    class_names=[\"No Disease\", \"Disease\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=8\n",
    ")\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Train vs Test Accuracy (Depth Experiment)\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- Train vs Test Accuracy for different tree depths ---\n",
    "\n",
    "depths = [1, 2, 3, 4, 5, 6, 8, 10]\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for d in depths:\n",
    "    model = Pipeline([\n",
    "        ('pre', pre),\n",
    "        ('model', DecisionTreeClassifier(max_depth=d, random_state=1955))\n",
    "    ])\n",
    "    model.fit(Xtr, ytr)\n",
    "    train_acc.append(model.score(Xtr, ytr))\n",
    "    test_acc.append(model.score(Xte, yte))\n",
    "\n",
    "print(\"Depths tested:\", depths)\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Test Accuracy :\", test_acc)\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Placeholder for later interpretation\n",
    "# ---------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "### ‚úçÔ∏è Interpretation Notes (to complete after running Section 3.3)\n",
    "\n",
    "- What features appear near the top of the tree? Why?  \n",
    "- Which splits seem most important?  \n",
    "- Compare training vs test accuracy:  \n",
    "  - Where does overfitting start?  \n",
    "  - Which depth gives the best generalization?  \n",
    "- Discuss the difference between logistic regression‚Äôs linear boundary \n",
    "  and the nonlinear, rule-based structure of a tree.\n",
    "\n",
    "---\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Append content and save notebook\n",
    "# ---------------------------------------------------------\n",
    "nb.cells.extend(cells)\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(nbf.writes(nb))\n",
    "\n",
    "print(\"Builder 4 applied ‚Äî Section 3.3 Decision Trees added to Module_03_Master.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cdf5a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Builder 5 applied ‚Äî Section 3.4 (Ensemble Methods) added to Module_03_Master.\n"
     ]
    }
   ],
   "source": [
    "# === Builder 5: Append Section 3.4 ‚Äî Ensemble Methods ===\n",
    "\n",
    "import os, nbformat as nbf\n",
    "\n",
    "OUT_DIR = \"module3_master\"\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"Module_03_Master.ipynb\")\n",
    "\n",
    "nb = nbf.read(open(OUT_PATH, \"r\", encoding=\"utf-8\"), as_version=4)\n",
    "\n",
    "def md(txt):\n",
    "    return nbf.v4.new_markdown_cell(txt)\n",
    "\n",
    "def code(txt):\n",
    "    return nbf.v4.new_code_cell(txt)\n",
    "\n",
    "cells = []\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Section Header\n",
    "# ---------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "# 3.4 ‚Äî Ensemble Methods (Random Forest & Boosting)\n",
    "\n",
    "In this section we explore **ensemble methods**, which combine multiple models to improve\n",
    "accuracy, stability, and generalization.\n",
    "\n",
    "We will train and compare:\n",
    "- **Random Forest** (bagging-based ensemble)  \n",
    "- **Gradient Boosting** (boosting-based model, similar to XGBoost)\n",
    "\n",
    "We will examine:\n",
    "- Performance metrics  \n",
    "- Feature importances  \n",
    "- Differences in model behavior  \n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Random Forest & Gradient Boosting Fit\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- 3.4 Ensemble Models: Random Forest & Gradient Boosting ---\n",
    "\n",
    "# Random Forest Classifier (Bagging)\n",
    "rf = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=200, \n",
    "        max_depth=None, \n",
    "        random_state=1955\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Gradient Boosting Classifier (Boosting; XGBoost-like behavior)\n",
    "gb = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('model', GradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=200,\n",
    "        max_depth=3,\n",
    "        random_state=1955\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit models\n",
    "rf.fit(Xtr, ytr)\n",
    "gb.fit(Xtr, ytr)\n",
    "\n",
    "# Predictions\n",
    "yhat_rf = rf.predict(Xte)\n",
    "yhat_gb = gb.predict(Xte)\n",
    "\n",
    "yprob_rf = rf.predict_proba(Xte)[:, 1]\n",
    "yprob_gb = gb.predict_proba(Xte)[:, 1]\n",
    "\n",
    "# Performance Metrics\n",
    "def metrics_dict(name, yhat, yprob):\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(yte, yhat),\n",
    "        \"Precision\": precision_score(yte, yhat),\n",
    "        \"Recall\": recall_score(yte, yhat),\n",
    "        \"F1\": f1_score(yte, yhat),\n",
    "        \"AUC\": roc_auc_score(yte, yprob),\n",
    "    }\n",
    "\n",
    "ensemble_results = pd.DataFrame([\n",
    "    metrics_dict(\"Random Forest\", yhat_rf, yprob_rf),\n",
    "    metrics_dict(\"Gradient Boosting\", yhat_gb, yprob_gb)\n",
    "])\n",
    "\n",
    "ensemble_results\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Feature Importances (RF + GB)\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- 3.4 Feature Importances ---\n",
    "\n",
    "# Extract feature names after one-hot encoding\n",
    "cat_features = pre.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(cat_cols)\n",
    "feature_names = np.concatenate([num_cols, cat_features])\n",
    "\n",
    "# Random Forest importances\n",
    "rf_importances = rf.named_steps['model'].feature_importances_\n",
    "\n",
    "# Gradient Boosting importances\n",
    "gb_importances = gb.named_steps['model'].feature_importances_\n",
    "\n",
    "# Plot importances side-by-side\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.barh(feature_names, rf_importances)\n",
    "plt.title(\"Random Forest Feature Importances\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.barh(feature_names, gb_importances)\n",
    "plt.title(\"Gradient Boosting Feature Importances\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Placeholder Markdown for interpretation\n",
    "# ---------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "### ‚úçÔ∏è Interpretation Notes (to complete after running Section 3.4)\n",
    "\n",
    "- Compare Random Forest vs Gradient Boosting metrics  \n",
    "- Discuss why boosting sometimes outperforms bagging  \n",
    "- Examine which features are most important and why  \n",
    "- Connect results to the conceptual slides on bagging vs boosting  \n",
    "- Note differences in model stability and overfitting behavior  \n",
    "\n",
    "---\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Append Builder 5 output to notebook\n",
    "# ---------------------------------------------------------\n",
    "nb.cells.extend(cells)\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(nbf.writes(nb))\n",
    "\n",
    "print(\"Builder 5 applied ‚Äî Section 3.4 (Ensemble Methods) added to Module_03_Master.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42cc8388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Builder 6 applied ‚Äî Section 3.5 Classification Metrics added to Module_03_Master.\n"
     ]
    }
   ],
   "source": [
    "# === Builder 6: Append Section 3.5 ‚Äî Classification Metrics (ROC, PR Curve, Confusion Matrix) ===\n",
    "\n",
    "import os, nbformat as nbf\n",
    "\n",
    "OUT_DIR = \"module3_master\"\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"Module_03_Master.ipynb\")\n",
    "\n",
    "nb = nbf.read(open(OUT_PATH, \"r\", encoding=\"utf-8\"), as_version=4)\n",
    "\n",
    "def md(txt): \n",
    "    return nbf.v4.new_markdown_cell(txt)\n",
    "\n",
    "def code(txt):\n",
    "    return nbf.v4.new_code_cell(txt)\n",
    "\n",
    "cells = []\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Markdown Header\n",
    "# ---------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "# 3.5 ‚Äî Classification Metrics  \n",
    "Confusion Matrix ‚Ä¢ ROC Curve ‚Ä¢ Precision‚ÄìRecall Curve ‚Ä¢ Threshold Effects\n",
    "\n",
    "In this section we evaluate classifiers using key metrics for binary classification.\n",
    "\n",
    "We will:\n",
    "- Visualize the **confusion matrix**  \n",
    "- Plot the **ROC curve** and compute **AUC**  \n",
    "- Plot the **Precision‚ÄìRecall curve**  \n",
    "- Explore how **threshold changes** affect performance  \n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Confusion Matrix Visualization\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- 3.5 Confusion Matrix (Visualization) ---\n",
    "\n",
    "# yhat (class predictions) and yprob (probabilities) were created in Section 3.2\n",
    "\n",
    "cm = confusion_matrix(yte, yhat)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix ‚Äî Logistic Regression\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xticks([0,1], [\"Pred 0\", \"Pred 1\"])\n",
    "plt.yticks([0,1], [\"True 0\", \"True 1\"])\n",
    "\n",
    "for (i, j), value in np.ndenumerate(cm):\n",
    "    plt.text(j, i, f\"{value}\", ha='center', va='center', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "cm\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ROC Curve\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- ROC Curve & AUC ---\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(yte, yprob)\n",
    "auc = roc_auc_score(yte, yprob)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve ‚Äî Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Precision‚ÄìRecall Curve\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- Precision‚ÄìRecall Curve ---\n",
    "\n",
    "precisions, recalls, pr_thresholds = precision_recall_curve(yte, yprob)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision‚ÄìRecall Curve ‚Äî Logistic Regression\")\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Threshold Effects (Precision vs Recall)\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- Threshold Effects on Precision & Recall ---\n",
    "\n",
    "test_thresholds = [0.2, 0.5, 0.8]\n",
    "\n",
    "for t in test_thresholds:\n",
    "    preds = (yprob >= t).astype(int)\n",
    "    prec = precision_score(yte, preds)\n",
    "    rec  = recall_score(yte, preds)\n",
    "    print(f\"Threshold={t:.2f} ‚Üí Precision={prec:.3f} | Recall={rec:.3f}\")\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Placeholder Markdown\n",
    "# ---------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "### ‚úçÔ∏è Interpretation Notes (to complete after running Section 3.5)\n",
    "\n",
    "- What do the confusion matrix values mean in context?  \n",
    "- Explain the shape of the ROC curve and why AUC matters  \n",
    "- Compare ROC vs Precision‚ÄìRecall curves  \n",
    "- Explain how lowering or raising the threshold changes FP, FN, precision, and recall  \n",
    "- Provide examples of when you would prefer:  \n",
    "  - High recall  \n",
    "  - High precision  \n",
    "  - High AUC  \n",
    "\n",
    "---\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Append & Save Notebook\n",
    "# ---------------------------------------------------------\n",
    "nb.cells.extend(cells)\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(nbf.writes(nb))\n",
    "\n",
    "print(\"Builder 6 applied ‚Äî Section 3.5 Classification Metrics added to Module_03_Master.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c6f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Builder 7 applied ‚Äî Section 3.6 added to Module_03_Master. Module 3 build complete!\n"
     ]
    }
   ],
   "source": [
    "# === Builder 7: Append Section 3.6 ‚Äî Model Tuning & Validation ===\n",
    "\n",
    "import os, nbformat as nbf\n",
    "\n",
    "OUT_DIR = \"module3_master\"\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"Module_03_Master.ipynb\")\n",
    "\n",
    "# Load existing notebook\n",
    "nb = nbf.read(open(OUT_PATH, \"r\", encoding=\"utf-8\"), as_version=4)\n",
    "\n",
    "def md(txt):\n",
    "    return nbf.v4.new_markdown_cell(txt)\n",
    "\n",
    "def code(txt):\n",
    "    return nbf.v4.new_code_cell(txt)\n",
    "\n",
    "cells = []\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Section Header\n",
    "# ---------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "# 3.6 ‚Äî Model Tuning & Validation\n",
    "\n",
    "In this section we explore **model tuning**, **validation curves**, and \n",
    "underfitting vs. overfitting. We will:\n",
    "\n",
    "- Tune Logistic Regression using the regularization parameter **C**\n",
    "- Tune Decision Trees using **max_depth**\n",
    "- Use `validation_curve` for visual inspection\n",
    "- Use GridSearchCV for deeper searches\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Validation Curve ‚Äî Logistic Regression (C parameter)\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- 3.6 Validation Curve: Logistic Regression C parameter ---\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# Values of C to test (inverse of regularization strength)\n",
    "C_values = np.logspace(-3, 3, 7)\n",
    "\n",
    "train_scores, val_scores = validation_curve(\n",
    "    estimator=log_reg, \n",
    "    X=Xtr, y=ytr,\n",
    "    param_name=\"model__C\",\n",
    "    param_range=C_values,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.semilogx(C_values, train_mean, marker=\"o\", label=\"Train Accuracy\")\n",
    "plt.semilogx(C_values, val_mean, marker=\"s\", label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"C (inverse of regularization strength)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation Curve ‚Äî Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Validation Curve ‚Äî Decision Tree (max_depth)\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- 3.6 Validation Curve: Decision Tree max_depth ---\n",
    "\n",
    "depth_range = [1, 2, 3, 4, 5, 6, 8, 10]\n",
    "\n",
    "train_scores, val_scores = validation_curve(\n",
    "    estimator=Pipeline([('pre', pre), ('model', DecisionTreeClassifier(random_state=1955))]),\n",
    "    X=Xtr, y=ytr,\n",
    "    param_name=\"model__max_depth\",\n",
    "    param_range=depth_range,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(depth_range, train_mean, marker=\"o\", label=\"Train Accuracy\")\n",
    "plt.plot(depth_range, val_mean, marker=\"s\", label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Tree max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation Curve ‚Äî Decision Tree\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Simple GridSearchCV ‚Äî Logistic Regression C\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- 3.6 GridSearchCV: Logistic Regression C ---\n",
    "\n",
    "grid_C = {\"model__C\": np.logspace(-3, 3, 10)}\n",
    "\n",
    "gs_log = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=grid_C,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_log.fit(Xtr, ytr)\n",
    "\n",
    "print(\"Best C:\", gs_log.best_params_['model__C'])\n",
    "print(\"Best CV Accuracy:\", gs_log.best_score_)\n",
    "\n",
    "best_log = gs_log.best_estimator_\n",
    "print(\"Test Accuracy:\", best_log.score(Xte, yte))\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Simple GridSearchCV ‚Äî Decision Tree Depth\n",
    "# ---------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- 3.6 GridSearchCV: Decision Tree max_depth ---\n",
    "\n",
    "param_depth = {\"model__max_depth\": [1, 2, 3, 4, 5, 6, 8, 10]}\n",
    "\n",
    "gs_tree = GridSearchCV(\n",
    "    estimator=Pipeline([('pre', pre), ('model', DecisionTreeClassifier(random_state=1955))]),\n",
    "    param_grid=param_depth,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_tree.fit(Xtr, ytr)\n",
    "\n",
    "print(\"Best max_depth:\", gs_tree.best_params_['model__max_depth'])\n",
    "print(\"Best CV Accuracy:\", gs_tree.best_score_)\n",
    "\n",
    "best_tree = gs_tree.best_estimator_\n",
    "print(\"Test Accuracy:\", best_tree.score(Xte, yte))\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Placeholder Markdown for future explanation\n",
    "# ---------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "### ‚úçÔ∏è Interpretation Notes (to fill after running Section 3.6)\n",
    "\n",
    "- In the logistic regression validation curve:\n",
    "  - Why does accuracy drop for very small C?\n",
    "  - Why might accuracy drop for very large C?\n",
    "- In the decision tree validation curve:\n",
    "  - Which depth leads to overfitting?\n",
    "  - Which depth appears to generalize best?\n",
    "- Compare GridSearchCV‚Äôs selected hyperparameters to the validation curve insights.\n",
    "- Discuss the trade-offs between:\n",
    "  - Underfitting vs Overfitting  \n",
    "  - Simplicity vs Complexity  \n",
    "  - Accuracy vs Interpretability  \n",
    "\n",
    "---\n",
    "\"\"\"))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Append cells and save\n",
    "# ---------------------------------------------------------\n",
    "nb.cells.extend(cells)\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(nbf.writes(nb))\n",
    "\n",
    "print(\"Builder 7 applied ‚Äî Section 3.6 added to Module_03_Master. Module 3 build complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cefa0d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7A Hands-On Exercise created at: module3_master/03_Hands_On_Exercise_A_HeartDisease.ipynb\n"
     ]
    }
   ],
   "source": [
    "# === Builder 3.7A: Create Hands-On Exercise A (Heart Disease Classification) ===\n",
    "\n",
    "import os, nbformat as nbf\n",
    "\n",
    "OUT_DIR = \"module3_master\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"03_Hands_On_Exercise_A_HeartDisease.ipynb\")\n",
    "\n",
    "def md(txt): \n",
    "    return nbf.v4.new_markdown_cell(txt)\n",
    "\n",
    "def code(txt): \n",
    "    return nbf.v4.new_code_cell(txt)\n",
    "\n",
    "nb = nbf.v4.new_notebook()\n",
    "cells = []\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# TITLE\n",
    "# -----------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "# üß™ Module 3 ‚Äî Hands-On Exercise A  \n",
    "## Heart Disease Classification (Logistic Regression ‚Ä¢ Trees ‚Ä¢ Ensembles ‚Ä¢ Metrics)\n",
    "\n",
    "### Goal\n",
    "- Compare **four classifiers** side-by-side  \n",
    "- Practice evaluating with **multiple metrics** (not just accuracy)  \n",
    "- Explore **thresholding**, **ROC curves**, and **model tuning**  \n",
    "- Gain intuition for **trade-offs** between interpretability and performance  \n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# IMPORTS + DATASET LOAD\n",
    "# -----------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Dataset helper\n",
    "from datasets_module3 import make_heart_disease_synth\n",
    "\n",
    "SEED = 1955\n",
    "\n",
    "# --- Step 1: Load Dataset ---\n",
    "df = make_heart_disease_synth(n=600, seed=SEED)\n",
    "df.head()\n",
    "\"\"\"))\n",
    "\n",
    "cells.append(md(\"\"\"\n",
    "### üîç Step 1 ‚Äî Explore the Dataset\n",
    "Use `df.head()`, `df.info()`, and `df.describe()` to understand the features and the target (`disease`).\n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# STEP 2 ‚Äî CLEAN & PREPARE\n",
    "# -----------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "## üßº Step 2 ‚Äî Clean & Prepare the Data\n",
    "We will:\n",
    "- Drop missing targets  \n",
    "- Identify numeric and categorical columns  \n",
    "- Build a preprocessing pipeline (impute + scale/encode)  \n",
    "\"\"\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "# --- Step 2: Clean & Prepare ---\n",
    "\n",
    "X = df.drop('disease', axis=1)\n",
    "y = df['disease']\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', num_pipe, num_cols),\n",
    "    ('cat', cat_pipe, cat_cols)\n",
    "])\n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# STEP 3 ‚Äî TRAIN/TEST SPLIT\n",
    "# -----------------------------------------------------------\n",
    "cells.append(md(\"## üîÄ Step 3 ‚Äî Train/Test Split\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "Xtr.shape, Xte.shape\n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# STEP 4 ‚Äî BASELINE LOGISTIC REGRESSION\n",
    "# -----------------------------------------------------------\n",
    "cells.append(md(\"## ‚öôÔ∏è Step 4 ‚Äî Logistic Regression (Baseline)\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "log_reg = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('model', LogisticRegression(max_iter=500, random_state=SEED))\n",
    "])\n",
    "\n",
    "log_reg.fit(Xtr, ytr)\n",
    "yhat_lr = log_reg.predict(Xte)\n",
    "yprob_lr = log_reg.predict_proba(Xte)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy :\", accuracy_score(yte, yhat_lr))\n",
    "print(\"Precision:\", precision_score(yte, yhat_lr))\n",
    "print(\"Recall   :\", recall_score(yte, yhat_lr))\n",
    "print(\"F1 Score :\", f1_score(yte, yhat_lr))\n",
    "print(\"AUC      :\", roc_auc_score(yte, yprob_lr))\n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# STEP 5 ‚Äî DECISION TREE\n",
    "# -----------------------------------------------------------\n",
    "cells.append(md(\"## üå≥ Step 5 ‚Äî Decision Tree Classifier\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "tree = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('model', DecisionTreeClassifier(max_depth=4, random_state=SEED))\n",
    "])\n",
    "\n",
    "tree.fit(Xtr, ytr)\n",
    "yhat_tree = tree.predict(Xte)\n",
    "yprob_tree = tree.predict_proba(Xte)[:, 1]\n",
    "\n",
    "print(\"Decision Tree Metrics:\")\n",
    "print(\"Accuracy :\", accuracy_score(yte, yhat_tree))\n",
    "print(\"Precision:\", precision_score(yte, yhat_tree))\n",
    "print(\"Recall   :\", recall_score(yte, yhat_tree))\n",
    "print(\"F1 Score :\", f1_score(yte, yhat_tree))\n",
    "print(\"AUC      :\", roc_auc_score(yte, yprob_tree))\n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# STEP 6 ‚Äî ENSEMBLE MODELS\n",
    "# -----------------------------------------------------------\n",
    "cells.append(md(\"## üå≤ Step 6 ‚Äî Random Forest & Gradient Boosting\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "# Random Forest\n",
    "rf = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('model', RandomForestClassifier(n_estimators=200, random_state=SEED))\n",
    "])\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('model', GradientBoostingClassifier(\n",
    "        learning_rate=0.05, \n",
    "        n_estimators=200, \n",
    "        max_depth=3,\n",
    "        random_state=SEED))\n",
    "])\n",
    "\n",
    "rf.fit(Xtr, ytr)\n",
    "gb.fit(Xtr, ytr)\n",
    "\n",
    "yhat_rf = rf.predict(Xte)\n",
    "yprob_rf = rf.predict_proba(Xte)[:, 1]\n",
    "\n",
    "yhat_gb = gb.predict(Xte)\n",
    "yprob_gb = gb.predict_proba(Xte)[:, 1]\n",
    "\n",
    "print(\"Random Forest AUC:\", roc_auc_score(yte, yprob_rf))\n",
    "print(\"Gradient Boosting AUC:\", roc_auc_score(yte, yprob_gb))\n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# STEP 7 ‚Äî METRICS SUMMARY TABLE\n",
    "# -----------------------------------------------------------\n",
    "cells.append(md(\"## üìä Step 7 ‚Äî Compare All Models (Metrics Table)\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "def evaluate(name, pred, prob):\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(yte, pred),\n",
    "        \"Precision\": precision_score(yte, pred),\n",
    "        \"Recall\": recall_score(yte, pred),\n",
    "        \"F1\": f1_score(yte, pred),\n",
    "        \"AUC\": roc_auc_score(yte, prob)\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    evaluate(\"Logistic Regression\", yhat_lr, yprob_lr),\n",
    "    evaluate(\"Decision Tree\", yhat_tree, yprob_tree),\n",
    "    evaluate(\"Random Forest\", yhat_rf, yprob_rf),\n",
    "    evaluate(\"Gradient Boosting\", yhat_gb, yprob_gb)\n",
    "])\n",
    "\n",
    "results.sort_values(\"AUC\", ascending=False)\n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# STEP 8 ‚Äî ROC CURVES FOR ALL MODELS\n",
    "# -----------------------------------------------------------\n",
    "cells.append(md(\"## üìà Step 8 ‚Äî ROC Curves (All Models)\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "plt.figure(figsize=(7,6))\n",
    "\n",
    "for name, prob in [\n",
    "    (\"Logistic\", yprob_lr),\n",
    "    (\"Tree\", yprob_tree),\n",
    "    (\"RF\", yprob_rf),\n",
    "    (\"GB\", yprob_gb)\n",
    "]:\n",
    "    fpr, tpr, _ = roc_curve(yte, prob)\n",
    "    plt.plot(fpr, tpr, label=name)\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves ‚Äî All Models\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# STEP 9 ‚Äî GRID SEARCH\n",
    "# -----------------------------------------------------------\n",
    "cells.append(md(\"## üõ†Ô∏è Step 9 ‚Äî Model Tuning (Grid Search)\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "params = {\"model__max_depth\": [2,3,4,5,6,8]}\n",
    "\n",
    "gs_tree = GridSearchCV(\n",
    "    Pipeline([('pre', pre), ('model', DecisionTreeClassifier(random_state=SEED))]),\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_tree.fit(Xtr, ytr)\n",
    "\n",
    "print(\"Best Tree Depth:\", gs_tree.best_params_['model__max_depth'])\n",
    "print(\"Best CV Acc    :\", gs_tree.best_score_)\n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# STEP 10 ‚Äî REFLECTION\n",
    "# -----------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "## üß† Step 10 ‚Äî Reflection Questions\n",
    "\n",
    "- Which model performed best overall? Why?  \n",
    "- Which metric (Accuracy, Precision, Recall, F1, AUC) changed your opinion the most?  \n",
    "- When might you prefer Logistic Regression over Random Forest?  \n",
    "- Would you deploy Gradient Boosting if interpretability mattered?  \n",
    "- How did tuning the Decision Tree affect performance?  \n",
    "\n",
    "---\n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# SAVE THE NOTEBOOK\n",
    "# -----------------------------------------------------------\n",
    "nb[\"cells\"] = cells\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(nbf.writes(nb))\n",
    "\n",
    "print(\"3.7A Hands-On Exercise created at:\", OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f408e2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7B (Spam) Hands-On Notebook CREATED at: module3_master/03_Hands_On_Exercise_B_Spam.ipynb\n"
     ]
    }
   ],
   "source": [
    "# === Builder 3.7B: Create Hands-On Exercise B (Spam Classification) ===\n",
    "\n",
    "import os, nbformat as nbf\n",
    "\n",
    "OUT_DIR = \"module3_master\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"03_Hands_On_Exercise_B_Spam.ipynb\")\n",
    "\n",
    "def md(text):\n",
    "    return nbf.v4.new_markdown_cell(text)\n",
    "\n",
    "def code(text):\n",
    "    return nbf.v4.new_code_cell(text)\n",
    "\n",
    "nb = nbf.v4.new_notebook()\n",
    "cells = []\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# TITLE\n",
    "# -----------------------------------------------------------\n",
    "cells.append(md(\"\"\"\n",
    "# üß™ Module 3 ‚Äî Hands-On Exercise B  \n",
    "## Spam Classification (Binary Classification)\n",
    "\n",
    "### Goal\n",
    "- Compare **four classifiers** on a spam-detection dataset  \n",
    "- Focus on *probabilities, thresholds, and trade-offs*  \n",
    "- Assess models using **precision, recall, F1, AUC, accuracy**  \n",
    "- Visualize **ROC curves**  \n",
    "- Perform simple **hyperparameter tuning**\n",
    "\n",
    "The dataset is synthetic but realistic, inspired by engineered text features\n",
    "(e.g., number of links, caps, free-domain senders, spammy words, etc.).\n",
    "\"\"\"))\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# IMPORTS + DATA LOADING\n",
    "# -----------------------------------------------------------\n",
    "cells.append(code(\"\"\"\n",
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Dataset helper\n",
    "from datasets_module3 import make_spam_synth\n",
    "\n",
    "SEED = 1955\n",
    "\n",
    "# --- Step 1: Load Dataset ---\n",
    "df = make_spam_synth(n=1000, seed=SEED)\n",
    "df.head()\n",
    "\"\"\"))\n",
    "\n",
    "cells.append(md(\"\"\"\n",
    "### üîç Step 1 ‚Äî Explore the Dataset\n",
    "Use:\n",
    "```python\n",
    "df.info()\n",
    "df.describe()\n",
    "df['spam'].value_counts()\n",
    "to understand feature distributions and class balance.\n",
    "\"\"\"))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#STEP 2 ‚Äî CLEAN & PREPARE\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "cells.append(md(\"\"\"\n",
    "\n",
    "üßº Step 2 ‚Äî Clean & Prepare the Data\n",
    "\n",
    "We will:\n",
    "\n",
    "Identify numeric and categorical columns\n",
    "\n",
    "Build preprocessing pipeline\n",
    "\n",
    "median imputation (numeric)\n",
    "\n",
    "most-frequent imputation (categorical)\n",
    "\n",
    "scaling + one-hot\n",
    "\"\"\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "\n",
    "--- Step 2: Clean & Prepare ---\n",
    "\n",
    "X = df.drop('spam', axis=1)\n",
    "y = df['spam']\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "('imputer', SimpleImputer(strategy='median')),\n",
    "('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "('num', num_pipe, num_cols),\n",
    "('cat', cat_pipe, cat_cols)\n",
    "])\n",
    "\"\"\"))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#STEP 3 ‚Äî SPLIT\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "cells.append(md(\"## üîÄ Step 3 ‚Äî Train/Test Split\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "Xtr.shape, Xte.shape\n",
    "\"\"\"))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#STEP 4 ‚Äî LOGISTIC REGRESSION\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "cells.append(md(\"## ‚öôÔ∏è Step 4 ‚Äî Logistic Regression (Baseline)\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "log_reg = Pipeline([\n",
    "('pre', pre),\n",
    "('model', LogisticRegression(max_iter=500, random_state=SEED))\n",
    "])\n",
    "\n",
    "log_reg.fit(Xtr, ytr)\n",
    "yhat_lr = log_reg.predict(Xte)\n",
    "yprob_lr = log_reg.predict_proba(Xte)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy :\", accuracy_score(yte, yhat_lr))\n",
    "print(\"Precision:\", precision_score(yte, yhat_lr))\n",
    "print(\"Recall :\", recall_score(yte, yhat_lr))\n",
    "print(\"F1 Score :\", f1_score(yte, yhat_lr))\n",
    "print(\"AUC :\", roc_auc_score(yte, yprob_lr))\n",
    "\"\"\"))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#STEP 5 ‚Äî DECISION TREE\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "cells.append(md(\"## üå≥ Step 5 ‚Äî Decision Tree Classifier\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "tree = Pipeline([\n",
    "('pre', pre),\n",
    "('model', DecisionTreeClassifier(max_depth=4, random_state=SEED))\n",
    "])\n",
    "\n",
    "tree.fit(Xtr, ytr)\n",
    "yhat_tree = tree.predict(Xte)\n",
    "yprob_tree = tree.predict_proba(Xte)[:, 1]\n",
    "\n",
    "print(\"Decision Tree Metrics:\")\n",
    "print(\"Accuracy :\", accuracy_score(yte, yhat_tree))\n",
    "print(\"Precision:\", precision_score(yte, yhat_tree))\n",
    "print(\"Recall :\", recall_score(yte, yhat_tree))\n",
    "print(\"F1 Score :\", f1_score(yte, yhat_tree))\n",
    "print(\"AUC :\", roc_auc_score(yte, yprob_tree))\n",
    "\"\"\"))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#STEP 6 ‚Äî ENSEMBLES\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "cells.append(md(\"## üå≤ Step 6 ‚Äî Random Forest & Gradient Boosting\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "\n",
    "Random Forest\n",
    "\n",
    "rf = Pipeline([\n",
    "('pre', pre),\n",
    "('model', RandomForestClassifier(n_estimators=200, random_state=SEED))\n",
    "])\n",
    "\n",
    "Gradient Boosting\n",
    "\n",
    "gb = Pipeline([\n",
    "('pre', pre),\n",
    "('model', GradientBoostingClassifier(\n",
    "learning_rate=0.05,\n",
    "n_estimators=200,\n",
    "max_depth=3,\n",
    "random_state=SEED))\n",
    "])\n",
    "\n",
    "rf.fit(Xtr, ytr)\n",
    "gb.fit(Xtr, ytr)\n",
    "\n",
    "yhat_rf = rf.predict(Xte)\n",
    "yprob_rf = rf.predict_proba(Xte)[:, 1]\n",
    "\n",
    "yhat_gb = gb.predict(Xte)\n",
    "yprob_gb = gb.predict_proba(Xte)[:, 1]\n",
    "\n",
    "print(\"Random Forest AUC:\", roc_auc_score(yte, yprob_rf))\n",
    "print(\"Gradient Boosting AUC:\", roc_auc_score(yte, yprob_gb))\n",
    "\"\"\"))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#STEP 7 ‚Äî METRICS SUMMARY TABLE\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "cells.append(md(\"## üìä Step 7 ‚Äî Compare All Models (Metrics Table)\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "def evaluate(name, pred, prob):\n",
    "return {\n",
    "\"Model\": name,\n",
    "\"Accuracy\": accuracy_score(yte, pred),\n",
    "\"Precision\": precision_score(yte, pred),\n",
    "\"Recall\": recall_score(yte, pred),\n",
    "\"F1\": f1_score(yte, pred),\n",
    "\"AUC\": roc_auc_score(yte, prob)\n",
    "}\n",
    "\n",
    "results = pd.DataFrame([\n",
    "evaluate(\"Logistic Regression\", yhat_lr, yprob_lr),\n",
    "evaluate(\"Decision Tree\", yhat_tree, yprob_tree),\n",
    "evaluate(\"Random Forest\", yhat_rf, yprob_rf),\n",
    "evaluate(\"Gradient Boosting\", yhat_gb, yprob_gb)\n",
    "])\n",
    "\n",
    "results.sort_values(\"AUC\", ascending=False)\n",
    "\"\"\"))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#STEP 8 ‚Äî ROC CURVES\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "cells.append(md(\"## üìà Step 8 ‚Äî ROC Curves (All Models)\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "plt.figure(figsize=(7,6))\n",
    "\n",
    "for name, prob in [\n",
    "(\"Logistic\", yprob_lr),\n",
    "(\"Tree\", yprob_tree),\n",
    "(\"RF\", yprob_rf),\n",
    "(\"GB\", yprob_gb)\n",
    "]:\n",
    "fpr, tpr, _ = roc_curve(yte, prob)\n",
    "plt.plot(fpr, tpr, label=name)\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves ‚Äî All Models\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#STEP 9 ‚Äî GRID SEARCH\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "cells.append(md(\"## üõ† Step 9 ‚Äî Model Tuning (Grid Search)\"))\n",
    "\n",
    "cells.append(code(\"\"\"\n",
    "params = {\"model__max_depth\": [2,3,4,5,6,8]}\n",
    "\n",
    "gs_tree = GridSearchCV(\n",
    "Pipeline([('pre', pre), ('model', DecisionTreeClassifier(random_state=SEED))]),\n",
    "param_grid=params,\n",
    "cv=5,\n",
    "scoring=\"accuracy\",\n",
    "n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_tree.fit(Xtr, ytr)\n",
    "\n",
    "print(\"Best Tree Depth:\", gs_tree.best_params_['model__max_depth'])\n",
    "print(\"Best CV Acc:\", gs_tree.best_score_)\n",
    "\"\"\"))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#STEP 10 ‚Äî REFLECTION\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "cells.append(md(\"\"\"\n",
    "\n",
    "üß† Step 10 ‚Äî Reflection Questions\n",
    "\n",
    "Which model performed best overall?\n",
    "\n",
    "Which metric (Accuracy, Precision, Recall, F1, AUC) changed your assessment the most?\n",
    "\n",
    "When is high precision more important than high recall in spam detection?\n",
    "\n",
    "Would you deploy a black-box model (RF/GB) if interpretability matters?\n",
    "\n",
    "How did tuning the Decision Tree affect performance?\n",
    "\n",
    "\"\"\"))\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#SAVE NOTEBOOK\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "nb[\"cells\"] = cells\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(nbf.writes(nb))\n",
    "\n",
    "print(\"3.7B (Spam) Hands-On Notebook CREATED at:\", OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59dc5e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7C Hands-On Exercise (Wine Multiclass) CREATED at: module3_master/03_Hands_On_Exercise_C_Wine.ipynb\n"
     ]
    }
   ],
   "source": [
    "# === Builder 3.7C: Create Hands-On Exercise C (Wine Multiclass Classification) ===\n",
    "\n",
    "import os\n",
    "import nbformat as nbf\n",
    "\n",
    "# ------------- Setup paths -------------\n",
    "OUT_DIR = \"module3_master\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"03_Hands_On_Exercise_C_Wine.ipynb\")\n",
    "\n",
    "# Helpers to build cells\n",
    "def md(text: str):\n",
    "    return nbf.v4.new_markdown_cell(text)\n",
    "\n",
    "def code(text: str):\n",
    "    return nbf.v4.new_code_cell(text)\n",
    "\n",
    "# Create a new notebook object\n",
    "nb = nbf.v4.new_notebook()\n",
    "cells = []\n",
    "\n",
    "# ------------- Title cell -------------\n",
    "cells.append(md(\n",
    "\"\"\"# üß™ Module 3 ‚Äî Hands-On Exercise C  \n",
    "## Wine Multiclass Classification (Red vs White vs Ros√©)\n",
    "\n",
    "### Goal\n",
    "- Work with a **multiclass** classification problem (3 wine types)  \n",
    "- Compare **four classifiers** (Logistic Regression, Decision Tree, Random Forest, Gradient Boosting)  \n",
    "- Use metrics such as **accuracy**, **macro precision**, **macro recall**, **macro F1**  \n",
    "- Visualize a **3√ó3 confusion matrix**  \n",
    "- Explore *one-vs-rest* ROC curves for each class  \n",
    "- Tune tree depth using **GridSearchCV**  \n",
    "\n",
    "The dataset is synthetic but realistic, based on typical wine chemistry properties.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "# ------------- Imports + dataset load -------------\n",
    "cells.append(code(\n",
    "\"\"\"# --- Imports & Data Loading ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_curve, roc_auc_score\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Dataset helper\n",
    "from datasets_module3 import make_wine_synth\n",
    "\n",
    "SEED = 1955\n",
    "\n",
    "# --- Step 1: Load Dataset ---\n",
    "df = make_wine_synth(n=800, seed=SEED)\n",
    "df.head()\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "cells.append(md(\n",
    "\"\"\"### üîç Step 1 ‚Äî Explore the Dataset\n",
    "\n",
    "Use:\n",
    "```python\n",
    "df.info()\n",
    "df.describe()\n",
    "df['wine_type'].value_counts()\n",
    "to understand:\n",
    "\n",
    "the feature distributions\n",
    "\n",
    "class balance among the three wine types\n",
    "\n",
    "which columns are numeric vs potential categorical fields.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "#------------- Step 2: Clean & Prepare -------------\n",
    "\n",
    "cells.append(md(\n",
    "\"\"\"## üßº Step 2 ‚Äî Clean & Prepare the Data\n",
    "\n",
    "We will:\n",
    "\n",
    "Separate features and target\n",
    "\n",
    "Build a preprocessing pipeline for numeric features\n",
    "\n",
    "(All features are numeric, so no one-hot encoding is needed here.)\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "cells.append(code(\n",
    "\"\"\"# --- Step 2: Clean & Prepare ---\n",
    "\n",
    "Features and target\n",
    "\n",
    "X = df.drop('wine_type', axis=1)\n",
    "y = df['wine_type'] # 0 = red, 1 = white, 2 = ros√©\n",
    "\n",
    "Identify numeric columns\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [] # no categorical columns in this synthetic dataset\n",
    "\n",
    "Preprocessing: numeric pipeline (median imputation + scaling)\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "('imputer', SimpleImputer(strategy='median')),\n",
    "('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "We still use a ColumnTransformer for consistency with other exercises\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "('num', num_pipe, num_cols)\n",
    "# no categorical block here\n",
    "])\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "#------------- Step 3: Train/Test Split -------------\n",
    "\n",
    "cells.append(md(\n",
    "\"\"\"## üîÄ Step 3 ‚Äî Train/Test Split\n",
    "\n",
    "We will hold out 20% of the data as a test set for final evaluation.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "cells.append(code(\n",
    "\"\"\"# --- Step 3: Split into train and test sets ---\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "Xtr.shape, Xte.shape, ytr.value_counts(), yte.value_counts()\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "#------------- Step 4: Logistic Regression -------------\n",
    "\n",
    "cells.append(md(\n",
    "\"\"\"## ‚öôÔ∏è Step 4 ‚Äî Multiclass Logistic Regression (One-vs-Rest / Softmax)\n",
    "\n",
    "Logistic Regression can be extended to multiclass prediction.\n",
    "We will fit a single model that predicts all three wine types.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "cells.append(code(\n",
    "\"\"\"# --- Step 4: Logistic Regression (multiclass) ---\n",
    "\n",
    "log_reg = Pipeline([\n",
    "('pre', pre),\n",
    "('model', LogisticRegression(\n",
    "max_iter=1000,\n",
    "multi_class='auto',\n",
    "random_state=SEED\n",
    "))\n",
    "])\n",
    "\n",
    "log_reg.fit(Xtr, ytr)\n",
    "\n",
    "yhat_lr = log_reg.predict(Xte)\n",
    "yprob_lr = log_reg.predict_proba(Xte) # shape: (n_samples, 3)\n",
    "\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy :\", accuracy_score(yte, yhat_lr))\n",
    "print(\"Macro Precision:\", precision_score(yte, yhat_lr, average='macro'))\n",
    "print(\"Macro Recall :\", recall_score(yte, yhat_lr, average='macro'))\n",
    "print(\"Macro F1 :\", f1_score(yte, yhat_lr, average='macro'))\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "#------------- Step 5: Decision Tree -------------\n",
    "\n",
    "cells.append(md(\n",
    "\"\"\"## üå≥ Step 5 ‚Äî Decision Tree Classifier\n",
    "\n",
    "We now fit a Decision Tree and compare it with Logistic Regression.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "cells.append(code(\n",
    "\"\"\"# --- Step 5: Decision Tree (multiclass) ---\n",
    "\n",
    "tree = Pipeline([\n",
    "('pre', pre),\n",
    "('model', DecisionTreeClassifier(\n",
    "max_depth=5,\n",
    "random_state=SEED\n",
    "))\n",
    "])\n",
    "\n",
    "tree.fit(Xtr, ytr)\n",
    "\n",
    "yhat_tree = tree.predict(Xte)\n",
    "yprob_tree = tree.predict_proba(Xte)\n",
    "\n",
    "print(\"Decision Tree Metrics:\")\n",
    "print(\"Accuracy :\", accuracy_score(yte, yhat_tree))\n",
    "print(\"Macro Precision:\", precision_score(yte, yhat_tree, average='macro'))\n",
    "print(\"Macro Recall :\", recall_score(yte, yhat_tree, average='macro'))\n",
    "print(\"Macro F1 :\", f1_score(yte, yhat_tree, average='macro'))\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "#------------- Step 6: Ensembles -------------\n",
    "\n",
    "cells.append(md(\n",
    "\"\"\"## üå≤ Step 6 ‚Äî Random Forest & Gradient Boosting (Multiclass)\n",
    "\n",
    "We now try ensemble models:\n",
    "\n",
    "Random Forest (bagging)\n",
    "\n",
    "Gradient Boosting (boosting-style, similar to XGBoost)\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "cells.append(code(\n",
    "\"\"\"# --- Step 6: Ensemble Models (RF & GB) ---\n",
    "\n",
    "rf = Pipeline([\n",
    "('pre', pre),\n",
    "('model', RandomForestClassifier(\n",
    "n_estimators=200,\n",
    "max_depth=None,\n",
    "random_state=SEED\n",
    "))\n",
    "])\n",
    "\n",
    "gb = Pipeline([\n",
    "('pre', pre),\n",
    "('model', GradientBoostingClassifier(\n",
    "learning_rate=0.05,\n",
    "n_estimators=200,\n",
    "max_depth=3,\n",
    "random_state=SEED\n",
    "))\n",
    "])\n",
    "\n",
    "rf.fit(Xtr, ytr)\n",
    "gb.fit(Xtr, ytr)\n",
    "\n",
    "yhat_rf = rf.predict(Xte)\n",
    "yprob_rf = rf.predict_proba(Xte)\n",
    "\n",
    "yhat_gb = gb.predict(Xte)\n",
    "yprob_gb = gb.predict_proba(Xte)\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy :\", accuracy_score(yte, yhat_rf))\n",
    "print(\"Macro Precision:\", precision_score(yte, yhat_rf, average='macro'))\n",
    "print(\"Macro Recall :\", recall_score(yte, yhat_rf, average='macro'))\n",
    "print(\"Macro F1 :\", f1_score(yte, yhat_rf, average='macro'))\n",
    "\n",
    "print(\"\\nGradient Boosting Metrics:\")\n",
    "print(\"Accuracy :\", accuracy_score(yte, yhat_gb))\n",
    "print(\"Macro Precision:\", precision_score(yte, yhat_gb, average='macro'))\n",
    "print(\"Macro Recall :\", recall_score(yte, yhat_gb, average='macro'))\n",
    "print(\"Macro F1 :\", f1_score(yte, yhat_gb, average='macro'))\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "#------------- Step 7: Metrics Summary Table -------------\n",
    "\n",
    "cells.append(md(\n",
    "\"\"\"## üìä Step 7 ‚Äî Metrics Summary (All Models)\n",
    "\n",
    "We will compare all models using macro-averaged Precision, Recall, and F1\n",
    "to treat all three classes equally.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "cells.append(code(\n",
    "\"\"\"# --- Step 7: Compare All Models (Metrics Table) ---\n",
    "\n",
    "def evaluate_multiclass(name, y_true, y_pred):\n",
    "return {\n",
    "\"Model\": name,\n",
    "\"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "\"Macro Precision\": precision_score(y_true, y_pred, average='macro'),\n",
    "\"Macro Recall\": recall_score(y_true, y_pred, average='macro'),\n",
    "\"Macro F1\": f1_score(y_true, y_pred, average='macro')\n",
    "}\n",
    "\n",
    "results = pd.DataFrame([\n",
    "evaluate_multiclass(\"Logistic Regression\", yte, yhat_lr),\n",
    "evaluate_multiclass(\"Decision Tree\", yte, yhat_tree),\n",
    "evaluate_multiclass(\"Random Forest\", yte, yhat_rf),\n",
    "evaluate_multiclass(\"Gradient Boosting\", yte, yhat_gb)\n",
    "])\n",
    "\n",
    "results.sort_values(\"Macro F1\", ascending=False)\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "#------------- Step 8: Confusion Matrix -------------\n",
    "\n",
    "cells.append(md(\n",
    "\"\"\"## üß© Step 8 ‚Äî Confusion Matrix (3√ó3)\n",
    "\n",
    "We now inspect a 3√ó3 confusion matrix to see which wine types\n",
    "are most often confused with each other.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "cells.append(code(\n",
    "\"\"\"# --- Step 8: Confusion Matrix (3√ó3) ---\n",
    "\n",
    "cm = confusion_matrix(yte, yhat_rf) # you can swap RF for any model\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix ‚Äî Random Forest\")\n",
    "plt.colorbar()\n",
    "plt.xticks([0,1,2], [\"Red\",\"White\",\"Ros√©\"])\n",
    "plt.yticks([0,1,2], [\"Red\",\"White\",\"Ros√©\"])\n",
    "\n",
    "for (i, j), value in np.ndenumerate(cm):\n",
    "plt.text(j, i, str(value), ha='center', va='center', fontsize=12)\n",
    "\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cm\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "#------------- Step 9: One-vs-Rest ROC Curves -------------\n",
    "\n",
    "cells.append(md(\n",
    "\"\"\"## üìà Step 9 ‚Äî One-vs-Rest ROC Curves (3 Classes)\n",
    "\n",
    "We can treat each class as \"positive\" in turn and compute a one-vs-rest ROC curve.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "cells.append(code(\n",
    "\"\"\"# --- Step 9: One-vs-Rest ROC Curves (using Random Forest probabilities) ---\n",
    "\n",
    "yprob_rf has shape (n_samples, 3)\n",
    "\n",
    "n_classes = 3\n",
    "plt.figure(figsize=(7,6))\n",
    "\n",
    "for c in range(n_classes):\n",
    "# Binarize: class c vs all others\n",
    "y_true_c = (yte == c).astype(int)\n",
    "y_score_c = yprob_rf[:, c]\n",
    "fpr, tpr, _ = roc_curve(y_true_c, y_score_c)\n",
    "auc_c = roc_auc_score(y_true_c, y_score_c)\n",
    "plt.plot(fpr, tpr, label=f\"Class {c} (AUC={auc_c:.2f})\")\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC Curves ‚Äî Random Forest\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "#------------- Step 10: Grid Search -------------\n",
    "\n",
    "cells.append(md(\n",
    "\"\"\"## üõ† Step 10 ‚Äî Simple Hyperparameter Tuning (Decision Tree Depth)\n",
    "\n",
    "We perform a small grid search over max_depth for a Decision Tree to see\n",
    "how depth affects multiclass classification performance.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "cells.append(code(\n",
    "\"\"\"# --- Step 10: GridSearchCV on Decision Tree max_depth ---\n",
    "\n",
    "param_grid = {\"model__max_depth\": [2,3,4,5,6,8]}\n",
    "\n",
    "gs_tree = GridSearchCV(\n",
    "estimator=Pipeline([\n",
    "('pre', pre),\n",
    "('model', DecisionTreeClassifier(random_state=SEED))\n",
    "]),\n",
    "param_grid=param_grid,\n",
    "cv=5,\n",
    "scoring='accuracy',\n",
    "n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_tree.fit(Xtr, ytr)\n",
    "\n",
    "print(\"Best max_depth:\", gs_tree.best_params_['model__max_depth'])\n",
    "print(\"Best CV Accuracy:\", gs_tree.best_score_)\n",
    "print(\"Test Accuracy with best tree:\", gs_tree.best_estimator_.score(Xte, yte))\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "#------------- Reflection questions -------------\n",
    "\n",
    "cells.append(md(\n",
    "\"\"\"## üß† Reflection Questions\n",
    "\n",
    "Which model gave the best Macro F1 score?\n",
    "\n",
    "Did one model favor certain classes over others? (e.g., always predict \"red\")\n",
    "\n",
    "How does the confusion matrix help you understand which classes are hard to separate?\n",
    "\n",
    "Would you choose interpretability (Logistic, Tree) or performance (Random Forest, GB)\n",
    "for this task if you were a wine producer or quality-control analyst?\n",
    "\n",
    "How does tuning max_depth affect tree overfitting vs underfitting in this multiclass setting?\n",
    "\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "#------------- Save notebook -------------\n",
    "\n",
    "nb[\"cells\"] = cells\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(nbf.writes(nb))\n",
    "\n",
    "print(\"3.7C Hands-On Exercise (Wine Multiclass) CREATED at:\", OUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
