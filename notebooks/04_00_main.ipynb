{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3bf788",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tunnel-ai/way/blob/main/notebooks/04_00_main.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2268d7c",
   "metadata": {},
   "source": [
    "# Module 4 — Unsupervised Learning (Guided Discovery)\n",
    "\n",
    "\n",
    "This notebook is a **guided discovery walk-through** of unsupervised learning on our over used canonical synthetic transaction dataset.\n",
    "\n",
    "- We are **not** trying to predict a label \n",
    "- We are trying to **see structure**, **compress complexity**, and **spot what’s unusual**.\n",
    "- Labels (e.g., `is_fraud`) exist in the dataset, but we will treat them as a **diagnostic lens** used *after* exploration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead2f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Colab) First-time setup: clone repo + add src/ to Python path\n",
    "# If you're running locally, you likely don't need this cell.\n",
    "\n",
    "# !git clone https://github.com/tunnel-ai/way.git\n",
    "# import sys\n",
    "# sys.path.insert(0, \"/content/way/src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d4227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.generators.transaction_risk_dgp import generate_transaction_risk_dataset\n",
    "\n",
    "# Canonical dataset (do not modify generator... well I guess you can. But carefully... )\n",
    "df = generate_transaction_risk_dataset(seed=1955)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f855cf",
   "metadata": {},
   "source": [
    "## 1) First contact: what does “a transaction” look like?\n",
    "\n",
    "Unsupervised learning is, somewhat obviously, unusually sensitive to **feature choice**.\n",
    "\n",
    "We’ll start with a clean split:\n",
    "- **Features for unsupervised exploration**: a numeric “behavior” subset.\n",
    "- **Outcomes for later validation**: `is_fraud`, `transaction_loss_amount` (kept aside until later).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME_COLS = [\"is_fraud\", \"transaction_loss_amount\"]\n",
    "\n",
    "df.dtypes.astype(str).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness (MNAR is expected for some fields, so this is informative)\n",
    "df.isna().mean().sort_values(ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f579b04f",
   "metadata": {},
   "source": [
    "### Choose a behavior feature set (numeric-first)\n",
    "\n",
    "Start with **numeric behavioral signals** and avoid high-cardinality IDs at first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08679ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_numeric = [\n",
    "    \"transaction_amount\",\n",
    "    \"transaction_hour\",\n",
    "    \"transaction_day\",\n",
    "    \"account_age_days\",\n",
    "    \"customer_risk_score\",\n",
    "    \"prior_transaction_count\",\n",
    "    \"prior_fraud_count\",\n",
    "]\n",
    "\n",
    "NUM_FEATURES = [c for c in candidate_numeric if c in df.columns]\n",
    "X_num = df[NUM_FEATURES].copy()\n",
    "\n",
    "X_num.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c9f1ff",
   "metadata": {},
   "source": [
    "## 2) Scaling: making distances comparable\n",
    "\n",
    "K-Means, DBSCAN, and PCA all depend on geometry. Standardization makes each feature contribute on a comparable footing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_num)\n",
    "\n",
    "pd.DataFrame(X_scaled, columns=NUM_FEATURES).agg([\"mean\", \"std\"]).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f658bc2",
   "metadata": {},
   "source": [
    "## 3) Clustering with K-Means: a first partition of behavior\n",
    "\n",
    "K-Means forces every point into one of *k* groups. We'll start with a small k for interpretability. How should we choose k?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=1955)\n",
    "cluster_km = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "df_km = df.copy()\n",
    "df_km[\"cluster_kmeans\"] = cluster_km\n",
    "\n",
    "df_km[\"cluster_kmeans\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_km.groupby(\"cluster_kmeans\")[NUM_FEATURES].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c28cf8f",
   "metadata": {},
   "source": [
    "### Visualize clusters on two intuitive axes\n",
    "\n",
    "We’ll pick two human-readable features for a simple “story view.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feat = \"transaction_amount\" if \"transaction_amount\" in NUM_FEATURES else NUM_FEATURES[0]\n",
    "y_feat = \"customer_risk_score\" if \"customer_risk_score\" in NUM_FEATURES else NUM_FEATURES[1]\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(df_km[x_feat], df_km[y_feat], c=df_km[\"cluster_kmeans\"], s=10, alpha=0.5)\n",
    "plt.xlabel(x_feat)\n",
    "plt.ylabel(y_feat)\n",
    "plt.title(\"K-Means clusters (two-feature view)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd59923",
   "metadata": {},
   "source": [
    "### Internal coherence check: silhouette score (diagnostic)\n",
    "\n",
    "Silhouette score is useful, but it is not “truth.” Treat it as a consistency check, not an objective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(X_scaled, cluster_km)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c06fe",
   "metadata": {},
   "source": [
    "## 4) Density-based clustering (DBSCAN): allowing “noise”\n",
    "\n",
    "DBSCAN can label points as **noise** if they don’t belong to any dense region. Choosing `eps` is the main judgment call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b365e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nn = 10\n",
    "nn = NearestNeighbors(n_neighbors=k_nn)\n",
    "nn.fit(X_scaled)\n",
    "distances, _ = nn.kneighbors(X_scaled)\n",
    "\n",
    "k_dist = np.sort(distances[:, -1])\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(k_dist)\n",
    "plt.title(f\"k-distance plot (k={k_nn})\")\n",
    "plt.xlabel(\"Points sorted by distance\")\n",
    "plt.ylabel(f\"Distance to {k_nn}th nearest neighbor\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85868aa2",
   "metadata": {},
   "source": [
    "### Run DBSCAN\n",
    "\n",
    "Start with a heuristic `eps`, then adjust live to see how the “noise” rate changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c388e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = float(np.percentile(k_dist, 95))  # heuristic start; adjust as needed\n",
    "min_samples = 10\n",
    "\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "cluster_db = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "df_db = df.copy()\n",
    "df_db[\"cluster_dbscan\"] = cluster_db\n",
    "\n",
    "df_db[\"cluster_dbscan\"].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e92d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_db[\"cluster_dbscan\"] == -1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(df_db[x_feat], df_db[y_feat], c=df_db[\"cluster_dbscan\"], s=10, alpha=0.5)\n",
    "plt.xlabel(x_feat)\n",
    "plt.ylabel(y_feat)\n",
    "plt.title(\"DBSCAN clusters (+ noise = -1) (two-feature view)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25afdd98",
   "metadata": {},
   "source": [
    "## 5) Dimensionality reduction (PCA): compressing complexity\n",
    "\n",
    "PCA gives us a reduced space that helps visualization and sense-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=min(10, len(NUM_FEATURES)), random_state=1955)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "explained = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(np.cumsum(explained), marker=\"o\")\n",
    "plt.ylim(0, 1.01)\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "plt.title(\"PCA explained variance (cumulative)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "explained[:5], explained.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad4198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1, pc2 = X_pca[:, 0], X_pca[:, 1]\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(pc1, pc2, s=10, alpha=0.5)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA projection (unlabeled)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02caee79",
   "metadata": {},
   "source": [
    "### Overlay cluster assignments in PCA space\n",
    "\n",
    "Does structure become easier to see?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(pc1, pc2, c=cluster_km, s=10, alpha=0.5)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA space colored by K-Means clusters\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(pc1, pc2, c=cluster_db, s=10, alpha=0.5)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA space colored by DBSCAN (+ noise)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a54da",
   "metadata": {},
   "source": [
    "## 6) Anomaly detection: modeling normality\n",
    "\n",
    "Isolation Forest assigns an anomaly score based on how *easily* points are isolated by random splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c01d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=0.02,  # adjust \n",
    "    random_state=1955,\n",
    ")\n",
    "iso.fit(X_scaled)\n",
    "\n",
    "score_normal = iso.decision_function(X_scaled)\n",
    "anomaly_score = -score_normal  # higher = more unusual\n",
    "\n",
    "df_anom = df.copy()\n",
    "df_anom[\"anomaly_score\"] = anomaly_score\n",
    "\n",
    "df_anom[\"anomaly_score\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(df_anom[\"anomaly_score\"], bins=50, alpha=0.8)\n",
    "plt.xlabel(\"Anomaly score (higher = more unusual)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Isolation Forest anomaly score distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 300\n",
    "idx_top = np.argsort(anomaly_score)[-top_n:]\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(pc1, pc2, s=8, alpha=0.25)\n",
    "plt.scatter(pc1[idx_top], pc2[idx_top], s=15, alpha=0.9)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(f\"Top {top_n} anomalies highlighted in PCA space\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602d471",
   "metadata": {},
   "source": [
    "## 7) Reveal labels as validation (not as targets)\n",
    "\n",
    "Now we can cheat. Check whether the discovered structure lines up with outcomes like fraud prevalence or loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a7ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fraud = df[\"is_fraud\"].astype(int)\n",
    "y_loss = df[\"transaction_loss_amount\"]\n",
    "\n",
    "pd.DataFrame({\"cluster\": cluster_km, \"is_fraud\": y_fraud}).groupby(\"cluster\")[\"is_fraud\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.98\n",
    "threshold = np.quantile(df_anom[\"anomaly_score\"], q)\n",
    "mask_top = df_anom[\"anomaly_score\"] >= threshold\n",
    "\n",
    "fraud_rate_overall = y_fraud.mean()\n",
    "fraud_rate_top = y_fraud[mask_top].mean()\n",
    "\n",
    "fraud_rate_overall, fraud_rate_top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3961df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_top = y_loss[mask_top]\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"group\": [\"overall\", f\"top_anomaly_q{q}\"],\n",
    "    \"mean_loss\": [y_loss.mean(), loss_top.mean()],\n",
    "    \"median_loss\": [y_loss.median(), loss_top.median()],\n",
    "    \"p95_loss\": [y_loss.quantile(0.95), loss_top.quantile(0.95)],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae2dea8",
   "metadata": {},
   "source": [
    "## 8) Check in...\n",
    "\n",
    "Unsupervised evaluation is multi-evidence:\n",
    "- **Coherence** (internal consistency)\n",
    "- **Visualization** (structure that persists in reduced space)\n",
    "- **Domain validation** (clusters/anomalies that match meaningful behavior)\n",
    "\n",
    "Something to think about\n",
    "> With a limited budget (money, time etc), where would you look first—and why?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
