{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a00b744",
   "metadata": {},
   "source": [
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tunnel-ai/way/blob/main/notebooks/02_00_main.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a50aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Course setup (un comment in run if using colab) ---\n",
    "#!git clone https://github.com/tunnel-ai/way.git\n",
    "#import sys; sys.path.insert(0, \"/content/way/src\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c59e58",
   "metadata": {},
   "source": [
    "# Module 2 — Supervised Learning: Regression \n",
    "\n",
    "**Target:** `transaction_loss_amount` (continuous, zero-inflated; heavy right tail for fraud cases)  \n",
    "**dataset:** Same as the prior one. `core.generators.transaction_risk_dgp.generate_transaction_risk_dataset(seed=1955)`  \n",
    "\n",
    "**How to run (Colab):**\n",
    "1. Open this notebook from GitHub with the **Open in Colab** button. \n",
    "2. Run the first cell (it clones the repo and sets `sys.path`). It might be commented out, if so uncomment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "RANDOM_STATE = 1955\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b972d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load canonical dataset (don't modify generator) --------------------------\n",
    "from core.generators.transaction_risk_dgp import generate_transaction_risk_dataset\n",
    "\n",
    "df = generate_transaction_risk_dataset(seed=RANDOM_STATE)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ef54f",
   "metadata": {},
   "source": [
    "## 1) Problem framing: why regression is tricky here\n",
    "\n",
    "`transaction_loss_amount` is **zero** for non-fraud transactions and **positive / heavy-tailed** for fraud transactions. So we have **zero-inflated, right-skewed** target distribution.\n",
    "\n",
    "It's a common in practice (e.g., claims, chargebacks, returns): many zeros, a few large outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911290b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Target distribution: zeros + heavy tail ----------------------------------\n",
    "TARGET = \"transaction_loss_amount\"\n",
    "\n",
    "y = df[TARGET]\n",
    "zero_rate = (y == 0).mean()\n",
    "\n",
    "print(f\"Rows: {len(df):,}\")\n",
    "print(f\"Zero rate in {TARGET}: {zero_rate:.1%}\")\n",
    "print(\"Target quantiles (including zeros):\")\n",
    "display(y.quantile([0, .5, .9, .95, .99, .995, .999]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(y, bins=100)\n",
    "ax.set_title(f\"Histogram of {TARGET} (raw scale)\")\n",
    "ax.set_xlabel(TARGET)\n",
    "ax.set_ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(np.log1p(y), bins=100)\n",
    "ax.set_title(f\"Histogram of log1p({TARGET})\")\n",
    "ax.set_xlabel(f\"log1p({TARGET})\")\n",
    "ax.set_ylabel(\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da06703",
   "metadata": {},
   "source": [
    "## 2) Train/test split + feature audit\n",
    "\n",
    "We're going to build a fairly minimal (time!) **baseline pipeline** to manage:\n",
    "- numeric features with missing values (impute + optional scaling)\n",
    "- categorical features with missing values (impute + one-hot encoding)\n",
    "- **high-cardinality** `merchant_id` (...carefully)\n",
    "\n",
    "We will not “clean” the dataset outside pipelines, the preprocessing stays inside the model pipeline to avoid leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8208afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define features / targets ------------------------------------------------\n",
    "DROP = [TARGET]  # regression target\n",
    "\n",
    "X = df.drop(columns=DROP)\n",
    "y = df[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = X_train.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "numeric_cols = [c for c in X_train.columns if c not in categorical_cols]\n",
    "\n",
    "print(\"n_train:\", X_train.shape, \"n_test:\", X_test.shape)\n",
    "print(\"Categorical:\", categorical_cols)\n",
    "print(\"Numeric (first 15):\", numeric_cols[:15])\n",
    "\n",
    "# Quick missingness + cardinality audit\n",
    "miss = X_train.isna().mean().sort_values(ascending=False)\n",
    "card = {c: X_train[c].nunique(dropna=True) for c in categorical_cols}\n",
    "card_s = pd.Series(card).sort_values(ascending=False)\n",
    "\n",
    "display(pd.DataFrame({\"missing_rate\": miss}).head(10))\n",
    "display(pd.DataFrame({\"n_unique\": card_s}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7f538",
   "metadata": {},
   "source": [
    "## 3) Baselines: “predict the mean” and “predict zero”\n",
    "\n",
    "Two baselines:\n",
    "\n",
    "1) **Mean baseline**: always predict the mean of the training target. Often surprisingly useful. Maybe not here. \n",
    "2) **Zero baseline**: always predict 0 (often really strong when there are many zeros)\n",
    "\n",
    "If a model *can’t* beat these, it’s not learning a useful signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4489b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_report(y_true, y_pred, label=\"model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return pd.Series({\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}, name=label)\n",
    "\n",
    "mean_pred = np.full_like(y_test, fill_value=float(y_train.mean()), dtype=float)\n",
    "zero_pred = np.zeros_like(y_test, dtype=float)\n",
    "\n",
    "results = pd.concat(\n",
    "    [\n",
    "        regression_report(y_test, mean_pred, \"Baseline: mean(y_train)\"),\n",
    "        regression_report(y_test, zero_pred, \"Baseline: always 0\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ").T\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ba875",
   "metadata": {},
   "source": [
    "## 4) Linear regression with a real preprocessing pipeline\n",
    "\n",
    "Fit an **OLS linear regression** on a feature matrix that mixes:\n",
    "- numeric variables (e.g., `transaction_amount`, `account_age_days`, risk counts)\n",
    "- categorical variables (e.g., `channel`, `merchant_category`, `merchant_id`)\n",
    "\n",
    "Key design choice/warning: how to encode high-cardinality categories like `merchant_id`?\n",
    "\n",
    "We’ll start with OneHotEncoder using **frequency-based grouping** (not available in all sklearn versions... looking at you colab...).  \n",
    "\n",
    "If not available, we’ll fall back to plain one-hot with `handle_unknown='ignore'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocessing ------------------------------------------------------------\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        # Scaling isn't strictly required for OLS, but helps when we move to regularization.\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# OneHotEncoder behavior can vary slightly by sklearn version! (root of all Python ills...)\n",
    "# We'll try to enable frequency-based grouping to reduce merchant_id explosion.\n",
    "def make_ohe():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", min_frequency=50)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", make_ohe()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0.3,\n",
    ")\n",
    "\n",
    "ols_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ols_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ecc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fit + evaluate -----------------------------------------------------------\n",
    "ols_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ols_model.predict(X_test)\n",
    "\n",
    "results_ols = pd.concat(\n",
    "    [results, regression_report(y_test, y_pred, \"OLS + one-hot\")],\n",
    "    axis=0\n",
    ")\n",
    "results_ols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf510f",
   "metadata": {},
   "source": [
    "### Diagnostics: prediction scatter + residuals\n",
    "\n",
    "A linear model can be “good enough” on average while failing badly in the tail.  \n",
    "Because loss is heavy-tailed, look at:\n",
    "- predicted vs actual\n",
    "- residuals vs predicted\n",
    "- residual histogram (often skewed / heteroskedastic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858020c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = y_test - y_pred\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_pred, alpha=0.4)\n",
    "ax.set_title(\"Predicted vs actual (OLS)\")\n",
    "ax.set_xlabel(\"Actual\")\n",
    "ax.set_ylabel(\"Predicted\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_pred, resid, alpha=0.4)\n",
    "ax.axhline(0, linewidth=1)\n",
    "ax.set_title(\"Residuals vs predicted (OLS)\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(resid, bins=100)\n",
    "ax.set_title(\"Residual histogram (OLS)\")\n",
    "ax.set_xlabel(\"Residual\")\n",
    "ax.set_ylabel(\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da97229",
   "metadata": {},
   "source": [
    "## 5) A pragmatic fix: model the log-loss\n",
    "\n",
    "When targets are right-skewed, a common baseline improvement is to model:\n",
    "\n",
    "\\[\n",
    "\\log(1 + \\text{loss})\n",
    "\\]\n",
    "\n",
    "Then transform predictions back. This often improves RMSE and makes residuals behave better, but:\n",
    "- it changes the loss function implicitly\n",
    "- it can under-predict the extreme tail\n",
    "\n",
    "We’ll use `TransformedTargetRegressor` so the transform is handled safely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73edc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ols = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", TransformedTargetRegressor(\n",
    "            regressor=LinearRegression(),\n",
    "            func=np.log1p,\n",
    "            inverse_func=np.expm1\n",
    "        )),\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_ols.fit(X_train, y_train)\n",
    "y_pred_log = log_ols.predict(X_test)\n",
    "\n",
    "results_log = pd.concat(\n",
    "    [results_ols, regression_report(y_test, y_pred_log, \"OLS on log1p(loss)\")],\n",
    "    axis=0\n",
    ")\n",
    "results_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b03705",
   "metadata": {},
   "source": [
    "## 6) Polynomial regression (carefully)\n",
    "\n",
    "Polynomial terms can capture **nonlinearities** and **interactions** in a way that stays “linear in parameters.”  \n",
    "But polynomial expansion with many features can explode the feature space.\n",
    "\n",
    "So here we demonstrate polynomial regression on a **single predictor** (`transaction_amount`) as a controlled example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8080a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Polynomial regression demo: transaction_amount only ----------------------\n",
    "# This is intentionally small + interpretable.\n",
    "poly_X_train = X_train[[\"transaction_amount\"]].copy()\n",
    "poly_X_test  = X_test[[\"transaction_amount\"]].copy()\n",
    "\n",
    "poly_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"poly\", PolynomialFeatures(degree=3, include_bias=False)),\n",
    "        (\"ridge\", Ridge(alpha=1.0, random_state=RANDOM_STATE)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "poly_model.fit(poly_X_train, y_train)\n",
    "poly_pred = poly_model.predict(poly_X_test)\n",
    "\n",
    "poly_results = pd.concat(\n",
    "    [results_log, regression_report(y_test, poly_pred, \"Poly(deg=3) on transaction_amount\")],\n",
    "    axis=0\n",
    ")\n",
    "poly_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f77bc",
   "metadata": {},
   "source": [
    "## 7) Regularization: Ridge / Lasso / Elastic Net\n",
    "\n",
    "With many correlated predictors (and one-hot categories), OLS can be unstable.  \n",
    "Regularization adds a penalty term that controls coefficient magnitude:\n",
    "\n",
    "- **Ridge (L2)** shrinks coefficients smoothly (good with correlated features)\n",
    "- **Lasso (L1)** can drive some coefficients to 0 (feature selection)\n",
    "- **Elastic Net** mixes both\n",
    "\n",
    "We’ll tune hyperparameters with cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8afb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Shared pipeline pieces ---------------------------------------------------\n",
    "def make_reg_pipeline(regressor):\n",
    "    return Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", regressor)])\n",
    "\n",
    "param_grid = {\n",
    "    \"model__alpha\": [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Ridge\n",
    "ridge_pipe = make_reg_pipeline(Ridge(random_state=RANDOM_STATE))\n",
    "ridge_search = GridSearchCV(ridge_pipe, param_grid=param_grid, cv=cv, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "ridge_search.fit(X_train, y_train)\n",
    "\n",
    "# Lasso (may need more iterations)\n",
    "lasso_pipe = make_reg_pipeline(Lasso(max_iter=20000, random_state=RANDOM_STATE))\n",
    "lasso_search = GridSearchCV(lasso_pipe, param_grid=param_grid, cv=cv, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "lasso_search.fit(X_train, y_train)\n",
    "\n",
    "# Elastic Net\n",
    "enet_pipe = make_reg_pipeline(ElasticNet(max_iter=20000, random_state=RANDOM_STATE))\n",
    "enet_grid = {\n",
    "    \"model__alpha\": [0.01, 0.1, 1.0, 10.0],\n",
    "    \"model__l1_ratio\": [0.1, 0.5, 0.9],\n",
    "}\n",
    "enet_search = GridSearchCV(enet_pipe, param_grid=enet_grid, cv=cv, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "enet_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Ridge:\", ridge_search.best_params_)\n",
    "print(\"Best Lasso:\", lasso_search.best_params_)\n",
    "print(\"Best ElasticNet:\", enet_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0382df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluate best regularized models on the test set -------------------------\n",
    "ridge_best = ridge_search.best_estimator_\n",
    "lasso_best = lasso_search.best_estimator_\n",
    "enet_best  = enet_search.best_estimator_\n",
    "\n",
    "ridge_pred = ridge_best.predict(X_test)\n",
    "lasso_pred = lasso_best.predict(X_test)\n",
    "enet_pred  = enet_best.predict(X_test)\n",
    "\n",
    "final_results = pd.concat(\n",
    "    [\n",
    "        results_log,\n",
    "        regression_report(y_test, ridge_pred, \"Ridge (CV-tuned)\"),\n",
    "        regression_report(y_test, lasso_pred, \"Lasso (CV-tuned)\"),\n",
    "        regression_report(y_test, enet_pred, \"ElasticNet (CV-tuned)\"),\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "final_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b3a2b",
   "metadata": {},
   "source": [
    "## 8) High-cardinality `merchant_id`: a concrete experiment\n",
    "\n",
    "`merchant_id` is high-cardinality. One-hot encoding can:\n",
    "- create a **HUGE** sparse matrix\n",
    "- memorize merchant effects (sometimes helpful, sometimes leakage-ish depending on context)\n",
    "- increase variance if many merchants appear rarely\n",
    "\n",
    "A quick sanity check is to compare performance **with** and **without** `merchant_id`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compare a model with and without merchant_id -----------------------------\n",
    "X_train_no_mid = X_train.drop(columns=[\"merchant_id\"], errors=\"ignore\")\n",
    "X_test_no_mid  = X_test.drop(columns=[\"merchant_id\"], errors=\"ignore\")\n",
    "\n",
    "cat_no_mid = X_train_no_mid.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "num_no_mid = [c for c in X_train_no_mid.columns if c not in cat_no_mid]\n",
    "\n",
    "preprocess_no_mid = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_no_mid),\n",
    "        (\"cat\", Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                               (\"onehot\", make_ohe())]), cat_no_mid),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0.3,\n",
    ")\n",
    "\n",
    "ridge_no_mid = Pipeline(steps=[(\"preprocess\", preprocess_no_mid), (\"model\", Ridge(alpha=ridge_search.best_params_[\"model__alpha\"], random_state=RANDOM_STATE))])\n",
    "ridge_no_mid.fit(X_train_no_mid, y_train)\n",
    "pred_no_mid = ridge_no_mid.predict(X_test_no_mid)\n",
    "\n",
    "compare_mid = pd.concat(\n",
    "    [\n",
    "        regression_report(y_test, ridge_pred, \"Ridge (with merchant_id)\"),\n",
    "        regression_report(y_test, pred_no_mid, \"Ridge (without merchant_id)\"),\n",
    "    ],\n",
    "    axis=1\n",
    ").T\n",
    "\n",
    "compare_mid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73398e",
   "metadata": {},
   "source": [
    "## Some notes\n",
    "\n",
    "- **Zero inflation matters**: always benchmark against “predict 0” as well as “predict the mean.”\n",
    "- **Pipelines are useful... maybe even required?**: preprocessing belongs inside the model pipeline to avoid leakage.\n",
    "- **The metric is a choice**: MAE vs RMSE tells you whether you care more about typical errors or tail errors.\n",
    "- **Linear models are baselines**: they are fast, interpretable, and useful even when they are misspecified.\n",
    "- **High-cardinality categories... have to make decisions**: one-hot (with grouping), hashing, target encoding, or dropping the feature.\n",
    "\n",
    "## Check in-- how are we doing here? \n",
    "1. Load the canonical dataset and articulate why the regression target is structurally challenging.\n",
    "2. Build a preprocessing pipeline for mixed numeric/categorical data.\n",
    "3. Evaluate regression models using MAE, RMSE, and R².\n",
    "4. Use residual plots to diagnose common issues.\n",
    "5. Explain how Ridge/Lasso/ElasticNet change model behavior relative to OLS.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
