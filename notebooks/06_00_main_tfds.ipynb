{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cd099f3e",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tunnel-ai/way/blob/main/notebooks/06_00_main_tfds.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 06_00_main — CNNs on EuroSAT (TFDS)\n",
        "\n",
        "**Module 6: Neural Networks (vision anchor)**\n",
        "\n",
        "In this notebook:\n",
        "- Load **EuroSAT RGB** from **TensorFlow Datasets (TFDS)**\n",
        "- Compare a **dense network baseline** (flattened pixels) vs a **CNN**\n",
        "- Add one “guardrail” (early stopping) to stabilize training\n",
        "- Do a little lightweight **error analysis** (confusions + example mistakes)\n",
        "\n",
        "> the *same data* behaves very differently depending on whether the architecture **respects** spatial structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you're running in Colab, TFDS is usually already available.\n",
        "# This is a safe no-op if it's installed.\n",
        "!pip -q install -U tensorflow tensorflow-datasets\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"TFDS:\", tfds.__version__)\n",
        "\n",
        "# Reproducibility (enough for interpretable curves)\n",
        "tf.keras.utils.set_random_seed(1955)\n",
        "\n",
        "# (Optional) confirm GPU\n",
        "print(\"GPU available:\", bool(tf.config.list_physical_devices(\"GPU\")))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load EuroSAT RGB from TFDS\n",
        "\n",
        "TFDS provides EuroSAT in multiple variants. We will use **`eurosat/rgb`** (RGB images) to keep the workflow simple and Colab-friendly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EuroSAT in TFDS is typically a single split called \"train\".\n",
        "# We'll create our own train/val/test slices.\n",
        "SPLIT_TRAIN = \"train[:80%]\"\n",
        "SPLIT_VAL   = \"train[80%:90%]\"\n",
        "SPLIT_TEST  = \"train[90%:]\"\n",
        "\n",
        "(ds_train_raw, ds_val_raw, ds_test_raw), info = tfds.load(\n",
        "    \"eurosat/rgb\",\n",
        "    split=[SPLIT_TRAIN, SPLIT_VAL, SPLIT_TEST],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "print(info)\n",
        "label_names = info.features[\"label\"].names\n",
        "num_classes = info.features[\"label\"].num_classes\n",
        "print(\"Classes:\", num_classes)\n",
        "print(label_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Quick visual sanity-check\n",
        "\n",
        "What do the labels *mean* at 64×64 resolution, any classes look naturally confusable?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grab a small batch for inspection\n",
        "sample_images = []\n",
        "sample_labels = []\n",
        "for img, lab in ds_train_raw.take(20):\n",
        "    sample_images.append(img.numpy())\n",
        "    sample_labels.append(int(lab.numpy()))\n",
        "\n",
        "# Plot a grid\n",
        "cols = 5\n",
        "rows = int(np.ceil(len(sample_images) / cols))\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i, (img, lab) in enumerate(zip(sample_images, sample_labels), start=1):\n",
        "    plt.subplot(rows, cols, i)\n",
        "    plt.imshow(img)\n",
        "    plt.title(label_names[lab], fontsize=9)\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Data pipeline (tf.data)\n",
        "\n",
        "Very minimal pipeline here...:\n",
        "- Convert to float32\n",
        "- Normalize to **[0, 1]**\n",
        "- Batch + prefetch\n",
        "\n",
        "Normally you would want to bake in many of these steps into functions, leaving it out here for demo purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Preprocess inline using Dataset.map with a lambda (keeps the logic visible)\n",
        "ds_train = ds_train_raw.map(lambda x, y: (tf.image.convert_image_dtype(x, tf.float32), y), num_parallel_calls=AUTOTUNE)\n",
        "ds_val   = ds_val_raw.map(lambda x, y: (tf.image.convert_image_dtype(x, tf.float32), y), num_parallel_calls=AUTOTUNE)\n",
        "ds_test  = ds_test_raw.map(lambda x, y: (tf.image.convert_image_dtype(x, tf.float32), y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "ds_train = ds_train.shuffle(2048).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "ds_val   = ds_val.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "ds_test  = ds_test.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# Confirm shapes\n",
        "for xb, yb in ds_train.take(1):\n",
        "    print(\"X batch:\", xb.shape, xb.dtype)\n",
        "    print(\"y batch:\", yb.shape, yb.dtype)\n",
        "    IMG_SHAPE = xb.shape[1:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Baseline model (intentionally “wrong”): Dense NN on flattened pixels\n",
        "\n",
        "Flattening treats the image as just a long vector and destroys locality.  \n",
        "We're essentially asking: *what do we lose by ignoring spatial structure?*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dense_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=IMG_SHAPE),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "], name=\"dense_baseline\")\n",
        "\n",
        "dense_model.summary()\n",
        "\n",
        "dense_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS_BASELINE = 8\n",
        "\n",
        "history_dense = dense_model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_val,\n",
        "    epochs=EPOCHS_BASELINE,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot learning curves (baseline)\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(history_dense.history[\"accuracy\"], label=\"train acc\")\n",
        "plt.plot(history_dense.history[\"val_accuracy\"], label=\"val acc\")\n",
        "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.title(\"Dense baseline accuracy\")\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(history_dense.history[\"loss\"], label=\"train loss\")\n",
        "plt.plot(history_dense.history[\"val_loss\"], label=\"val loss\")\n",
        "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.title(\"Dense baseline loss\")\n",
        "plt.legend(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) CNN model: same data, different inductive bias\n",
        "\n",
        "A CNN assumes:\n",
        "- nearby pixels matter together (locality)\n",
        "- learned filters can be reused across the image (weight sharing)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=IMG_SHAPE),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.25), #this is sometimes controversial. Not cool anymore.\n",
        "    tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "], name=\"cnn_small\")\n",
        "\n",
        "cnn_model.summary()\n",
        "\n",
        "cnn_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 One training guardrail: Early stopping\n",
        "\n",
        "We’ll stop training when validation loss stops improving. (given we are doing this live... we are obviously going to cut some time/expense in favor of the demo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=2,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "EPOCHS_CNN = 15\n",
        "\n",
        "history_cnn = cnn_model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_val,\n",
        "    epochs=EPOCHS_CNN,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot learning curves (CNN)\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(history_cnn.history[\"accuracy\"], label=\"train acc\")\n",
        "plt.plot(history_cnn.history[\"val_accuracy\"], label=\"val acc\")\n",
        "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.title(\"CNN accuracy\")\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(history_cnn.history[\"loss\"], label=\"train loss\")\n",
        "plt.plot(history_cnn.history[\"val_loss\"], label=\"val loss\")\n",
        "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.title(\"CNN loss\")\n",
        "plt.legend(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Test-set evaluation\n",
        "\n",
        "Accuracy is not the only story, but it’s a good first check.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dense_test = dense_model.evaluate(ds_test, verbose=0)\n",
        "cnn_test   = cnn_model.evaluate(ds_test, verbose=0)\n",
        "\n",
        "print(\"Dense baseline — test loss, test acc:\", dense_test)\n",
        "print(\"CNN          — test loss, test acc:\", cnn_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Confusion matrix + quick error analysis\n",
        "\n",
        "Inspect:\n",
        "- which classes the model confuses\n",
        "- a handful of high-confidence mistakes (useful for discussion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect predictions on the test set\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_prob = []\n",
        "\n",
        "for xb, yb in ds_test:\n",
        "    probs = cnn_model.predict(xb, verbose=0)\n",
        "    preds = np.argmax(probs, axis=1)\n",
        "\n",
        "    y_true.extend(yb.numpy().tolist())\n",
        "    y_pred.extend(preds.tolist())\n",
        "    y_prob.extend(np.max(probs, axis=1).tolist())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "y_prob = np.array(y_prob)\n",
        "\n",
        "cm = tf.math.confusion_matrix(y_true, y_pred, num_classes=num_classes).numpy()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(cm)\n",
        "plt.title(\"CNN confusion matrix (test set)\")\n",
        "plt.xlabel(\"predicted\")\n",
        "plt.ylabel(\"true\")\n",
        "plt.colorbar()\n",
        "plt.xticks(range(num_classes), label_names, rotation=90, fontsize=8)\n",
        "plt.yticks(range(num_classes), label_names, fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# a few high-confidence mistakes\n",
        "# We'll scan the test set again, keep images for mistakes.\n",
        "mistake_imgs = []\n",
        "mistake_true = []\n",
        "mistake_pred = []\n",
        "mistake_conf = []\n",
        "\n",
        "for xb, yb in ds_test:\n",
        "    probs = cnn_model.predict(xb, verbose=0)\n",
        "    preds = np.argmax(probs, axis=1)\n",
        "    confs = np.max(probs, axis=1)\n",
        "\n",
        "    for i in range(xb.shape[0]):\n",
        "        true_i = int(yb[i].numpy())\n",
        "        pred_i = int(preds[i])\n",
        "        conf_i = float(confs[i])\n",
        "        if pred_i != true_i:\n",
        "            mistake_imgs.append(xb[i].numpy())\n",
        "            mistake_true.append(true_i)\n",
        "            mistake_pred.append(pred_i)\n",
        "            mistake_conf.append(conf_i)\n",
        "\n",
        "# Sort mistakes by confidence (descending)\n",
        "idx = np.argsort(-np.array(mistake_conf))\n",
        "\n",
        "top_k = 12\n",
        "idx = idx[:min(top_k, len(idx))]\n",
        "\n",
        "cols = 4\n",
        "rows = int(np.ceil(len(idx) / cols))\n",
        "plt.figure(figsize=(12, 8))\n",
        "for j, k in enumerate(idx, start=1):\n",
        "    plt.subplot(rows, cols, j)\n",
        "    plt.imshow(mistake_imgs[k]).astype(\"uint8\")\n",
        "    t = label_names[mistake_true[k]]\n",
        "    p = label_names[mistake_pred[k]]\n",
        "    c = mistake_conf[k]\n",
        "    plt.title(f\"true: {t}\\npred: {p} ({c:.2f})\", fontsize=8)\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Total test mistakes found: {len(mistake_imgs)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) (Optional) Transfer learning\n",
        "\n",
        "- Resize inputs to match a pretrained backbone\n",
        "- Freeze backbone, train a small head\n",
        "- Compare stability and accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUN_TRANSFER = False  # set True to  run the optional code below\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if RUN_TRANSFER:\n",
        "    # We'll use MobileNetV2 as a lightweight pretrained backbone.\n",
        "    # It expects larger images, so we'll resize on the fly in the pipeline.\n",
        "    TARGET_SIZE = (160, 160)\n",
        "\n",
        "    ds_train_tl = ds_train_raw.map(\n",
        "        lambda x, y: (tf.image.resize(tf.image.convert_image_dtype(x, tf.float32), TARGET_SIZE), y),\n",
        "        num_parallel_calls=AUTOTUNE\n",
        "    ).shuffle(2048).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "    ds_val_tl = ds_val_raw.map(\n",
        "        lambda x, y: (tf.image.resize(tf.image.convert_image_dtype(x, tf.float32), TARGET_SIZE), y),\n",
        "        num_parallel_calls=AUTOTUNE\n",
        "    ).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "    ds_test_tl = ds_test_raw.map(\n",
        "        lambda x, y: (tf.image.resize(tf.image.convert_image_dtype(x, tf.float32), TARGET_SIZE), y),\n",
        "        num_parallel_calls=AUTOTUNE\n",
        "    ).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "    backbone = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=TARGET_SIZE + (3,),\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "    backbone.trainable = False\n",
        "\n",
        "    tl_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=TARGET_SIZE + (3,)),\n",
        "        backbone,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
        "    ], name=\"mobilenetv2_transfer\")\n",
        "\n",
        "    tl_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    history_tl = tl_model.fit(\n",
        "        ds_train_tl,\n",
        "        validation_data=ds_val_tl,\n",
        "        epochs=10,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    tl_test = tl_model.evaluate(ds_test_tl, verbose=0)\n",
        "    print(\"Transfer learning — test loss, test acc:\", tl_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Check in:\n",
        "\n",
        "- The dense baseline *can* learn something, but it wastes capacity re-learning spatial structure.\n",
        "- The CNN improves by building the right bias into the architecture.\n",
        "- Training is not “set and forget”: early stopping (and other guardrails) prevent wasted compute and overfit.\n",
        "- Confusions are not just mistakes—they are clues about what the data makes inherently hard.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "06_00_main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
