{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e913a50",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]\n",
    "(https://colab.research.google.com/github/tunnel-ai/way/blob/main/notebooks/03_01_exercise_guided.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0429574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Course setup (uncomment and run if using Colab) --------------------------\n",
    "#!git clone https://github.com/tunnel-ai/way.git\n",
    "#import sys; sys.path.insert(0, \"/content/way/src\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf2493",
   "metadata": {},
   "source": [
    "# Module 3 — Exercise 01 (Guided): Fraud Classification\n",
    "\n",
    "**Role:** Guided practitioner (structured adaptation)\n",
    "\n",
    "**Target:** `is_fraud`  \n",
    "**Canonical dataset:** `generate_transaction_risk_dataset(seed=1955)`\n",
    "\n",
    "### What you will do\n",
    "You will adapt the Module 3 workflow by completing **targeted TODOs**.\n",
    "\n",
    "By the end, you should be able to:\n",
    "- Build a leakage-safe feature matrix for a binary classification target\n",
    "- Train a baseline and a logistic regression pipeline\n",
    "- Evaluate using **Precision–Recall** and **ROC** metrics (important for imbalanced data)\n",
    "- Choose a decision threshold (not just a probability model)\n",
    "\n",
    "> **Rules:** Use the canonical generator exactly as provided. Do not modify generator code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4305a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    "    precision_recall_curve,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 1955\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dcf074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the canonical dataset ------------------------------------------------\n",
    "from core.generators.transaction_risk_dgp import generate_transaction_risk_dataset\n",
    "\n",
    "df = generate_transaction_risk_dataset(seed=1955)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d42ce",
   "metadata": {},
   "source": [
    "## 1) Define target and leakage-safe features\n",
    "\n",
    "For **classification**, the target is `is_fraud`.\n",
    "\n",
    "**Leakage guardrail:** do *not* include variables that directly encode the outcome.\n",
    "- `transaction_loss_amount` is mechanically tied to fraud (it is >0 only when fraud occurs), so including it would leak the label.\n",
    "\n",
    "### TODO 1\n",
    "Create `y` as the `is_fraud` column and `X` as the remaining features **excluding**:\n",
    "- `is_fraud`\n",
    "- `transaction_loss_amount`\n",
    "\n",
    "Then print:\n",
    "- `y.mean()` (fraud rate)\n",
    "- the number of columns in `X`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ee0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: Define X and y (leakage-safe)\n",
    "TARGET = \"is_fraud\"\n",
    "LEAKAGE_EXCLUDE = [\"transaction_loss_amount\"]\n",
    "\n",
    "# --- your code here ------------------------------------------------------------\n",
    "# y = ...\n",
    "# X = ...\n",
    "\n",
    "print(\"Fraud rate:\", y.mean())\n",
    "print(\"X columns:\", X.shape[1])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ead624",
   "metadata": {},
   "source": [
    "## 2) Train/validation split (stratified)\n",
    "\n",
    "Fraud is rare, so we use a **stratified split** to preserve class balance.\n",
    "\n",
    "### TODO 2\n",
    "Create `X_train, X_val, y_train, y_val` using `train_test_split` with:\n",
    "- `test_size=0.25`\n",
    "- `random_state=RANDOM_STATE`\n",
    "- `stratify=y`\n",
    "\n",
    "Then print the fraud rate in train and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116cf800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2: Stratified split\n",
    "# X_train, X_val, y_train, y_val = ...\n",
    "\n",
    "print(\"Train fraud rate:\", y_train.mean())\n",
    "print(\"Val fraud rate:  \", y_val.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2ea07",
   "metadata": {},
   "source": [
    "## 3) Baseline model\n",
    "\n",
    "A good baseline for rare-event classification is the **majority-class** classifier.\n",
    "\n",
    "### TODO 3\n",
    "Fit a `DummyClassifier(strategy=\"most_frequent\")` and report:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "\n",
    "*Note:* The baseline may have high accuracy but terrible recall — that’s the point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3: Baseline classifier\n",
    "baseline = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# Fit\n",
    "# baseline.fit(...)\n",
    "\n",
    "# Predict class labels\n",
    "# y_pred_base = ...\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_base))\n",
    "print(\"Precision:\", precision_score(y_val, y_pred_base, zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred_base, zero_division=0))\n",
    "print(\"F1:\", f1_score(y_val, y_pred_base, zero_division=0))\n",
    "\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_val, y_pred_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080eb898",
   "metadata": {},
   "source": [
    "## 4) Preprocessing pipeline (impute + encode + scale)\n",
    "\n",
    "We will build a single sklearn **Pipeline** so that:\n",
    "- Imputation and encoding are learned **only on training data**\n",
    "- We avoid leakage during evaluation\n",
    "\n",
    "### TODO 4\n",
    "1) Identify:\n",
    "- `numeric_features`\n",
    "- `categorical_features`\n",
    "\n",
    "2) Create a `ColumnTransformer` named `preprocess` with:\n",
    "- Numeric: `SimpleImputer(strategy=\"median\")` then `StandardScaler()`\n",
    "- Categorical: `SimpleImputer(strategy=\"most_frequent\")` then `OneHotEncoder(handle_unknown=\"ignore\")`\n",
    "\n",
    "Hint: `X_train.dtypes` is useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4: Column lists and preprocess transformer\n",
    "# numeric_features = ...\n",
    "# categorical_features = ...\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "# preprocess = ColumnTransformer(...)\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3531a",
   "metadata": {},
   "source": [
    "## 5) Logistic regression model (interpretable baseline)\n",
    "\n",
    "### TODO 5\n",
    "Create a pipeline:\n",
    "- `(\"preprocess\", preprocess)`\n",
    "- `(\"model\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))`\n",
    "\n",
    "Then:\n",
    "- Fit on training data\n",
    "- Predict probabilities on validation (`predict_proba`) for ROC/PR metrics\n",
    "- Compute **ROC-AUC** and **PR-AUC** (Average Precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd6ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5: Logistic regression pipeline\n",
    "log_reg = Pipeline(steps=[\n",
    "    # (\"preprocess\", ...),\n",
    "    # (\"model\", ...),\n",
    "])\n",
    "\n",
    "# Fit\n",
    "# log_reg.fit(...)\n",
    "\n",
    "# Probabilities for the positive class\n",
    "# y_prob_lr = ...\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_val, y_prob_lr))\n",
    "print(\"PR-AUC (Avg Precision):\", average_precision_score(y_val, y_prob_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4144ca4f",
   "metadata": {},
   "source": [
    "### Visualize ROC and Precision–Recall curves\n",
    "\n",
    "For imbalanced classification, the **Precision–Recall** curve is often more informative than ROC.\n",
    "\n",
    "### TODO 6\n",
    "Plot both curves using `RocCurveDisplay.from_predictions` and `PrecisionRecallDisplay.from_predictions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be83c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 6: ROC and PR curves\n",
    "plt.figure()\n",
    "RocCurveDisplay.from_predictions(y_val, y_prob_lr)\n",
    "plt.title(\"Logistic Regression — ROC Curve\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "PrecisionRecallDisplay.from_predictions(y_val, y_prob_lr)\n",
    "plt.title(\"Logistic Regression — Precision–Recall Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639d6b2",
   "metadata": {},
   "source": [
    "## 6) Turn probabilities into decisions (choose a threshold)\n",
    "\n",
    "A classifier outputs probabilities, but operations often require **binary decisions** (flag / don’t flag).\n",
    "\n",
    "### TODO 7\n",
    "Use `precision_recall_curve` to compute precision, recall, thresholds.\n",
    "\n",
    "Then choose a threshold using **one** of these rules:\n",
    "- **Rule A:** smallest threshold that achieves **recall ≥ 0.80**\n",
    "- **Rule B:** threshold that **maximizes F1**\n",
    "\n",
    "After choosing a threshold, compute and print:\n",
    "- confusion matrix\n",
    "- precision / recall / F1\n",
    "\n",
    "*This is the key skill:* moving from model score to decision policy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0bb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 7: Threshold selection\n",
    "prec, rec, thresh = precision_recall_curve(y_val, y_prob_lr)\n",
    "\n",
    "# Note: precision_recall_curve returns thresholds of length n-1\n",
    "# You may want to align arrays: prec[:-1], rec[:-1], thresh\n",
    "\n",
    "# --- your code here ------------------------------------------------------------\n",
    "# chosen_threshold = ...\n",
    "\n",
    "y_pred_thresh = (y_prob_lr >= chosen_threshold).astype(int)\n",
    "\n",
    "print(\"Chosen threshold:\", chosen_threshold)\n",
    "print(\"Precision:\", precision_score(y_val, y_pred_thresh, zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred_thresh, zero_division=0))\n",
    "print(\"F1:\", f1_score(y_val, y_pred_thresh, zero_division=0))\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_val, y_pred_thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b45e5a",
   "metadata": {},
   "source": [
    "## 7) A nonlinear alternative: Decision Tree\n",
    "\n",
    "A single decision tree can capture **interactions** (e.g., risk score × channel × time), which logistic regression may miss.\n",
    "\n",
    "### TODO 8\n",
    "Fit a `DecisionTreeClassifier` inside the same preprocessing pipeline.\n",
    "Use a small tree to avoid extreme overfitting:\n",
    "- `max_depth=4`\n",
    "- `min_samples_leaf=200`\n",
    "\n",
    "Report ROC-AUC and PR-AUC on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c8c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 8: Decision tree pipeline\n",
    "tree_clf = Pipeline(steps=[\n",
    "    # (\"preprocess\", preprocess),\n",
    "    # (\"model\", DecisionTreeClassifier(...)),\n",
    "])\n",
    "\n",
    "# tree_clf.fit(...)\n",
    "# y_prob_tree = ...\n",
    "\n",
    "print(\"Tree ROC-AUC:\", roc_auc_score(y_val, y_prob_tree))\n",
    "print(\"Tree PR-AUC:\", average_precision_score(y_val, y_prob_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c349ecff",
   "metadata": {},
   "source": [
    "## 8) Short reflection (answer in 3–6 sentences each)\n",
    "\n",
    "1) Why can accuracy be misleading for rare-event classification?\n",
    "2) Which curve (ROC or Precision–Recall) changed your interpretation more, and why?\n",
    "3) What did threshold selection force you to think about that ROC-AUC alone does not?\n",
    "\n",
    "*(Write responses below as Markdown.)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d3a8e",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "1) \n",
    "\n",
    "2) \n",
    "\n",
    "3) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
