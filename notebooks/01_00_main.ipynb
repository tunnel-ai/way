{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ef899d",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]\n",
    "(https://colab.research.google.com/github/tunnel-ai/way/blob/main/notebooks/01_00_main.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62626192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Course setup (un comment in run if using colab) ---\n",
    "#!git clone https://github.com/tunnel-ai/way.git\n",
    "#import sys; sys.path.insert(0, \"/content/way/src\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd06fa",
   "metadata": {},
   "source": [
    "# Module 1 — AI, ML, and Data Science (Demo Notebook)\n",
    "\n",
    "This is the **instructor demo notebook** for Module 1. It is designed to run **top-to-bottom** with no external downloads. (the course 'package' should all be imported from the repo together...)\n",
    "\n",
    "**Canonical dataset:** synthetic transactional risk data generated deterministically via a local generator. We will use portions of this dataset in several modules. \n",
    "\n",
    "- Classification target (Module 1 focus): `is_fraud`\n",
    "- Regression target (Module 2): `transaction_loss_amount` (introduced briefly, used later)\n",
    "- Unsupervised (Module 4): behavioral structure + anomaly detection (used later)\n",
    "\n",
    "> A rough rule-- we *mostly* rely on generated data. This is not a course on data types, and time spent discussing data dictionaries is time not spent modeling. So we/I try to balance new interesting data with time/speed to modeling  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4148e35",
   "metadata": {},
   "source": [
    "## 0) Setup and data generation\n",
    "\n",
    "**Timebox:** ~10 minutes\n",
    "\n",
    "We import the course generator and materialize the dataset with a fixed seed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 1955\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Course dataset generator (local package)\n",
    "from core.generators.transaction_risk_dgp import (\n",
    "    generate_transaction_risk_dataset,\n",
    "    TransactionRiskConfig,\n",
    "    dataset_summary,\n",
    ")\n",
    "\n",
    "# Generate the canonical dataset (deterministic)\n",
    "df = generate_transaction_risk_dataset(seed=SEED)\n",
    "\n",
    "# Quick sanity check\n",
    "dataset_summary(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e145436d",
   "metadata": {},
   "source": [
    "## 1) Data dictionary (what each field means)\n",
    "\n",
    "**Timebox:** ~10 minutes\n",
    "\n",
    "A *data dictionary* is a practical artifact: it helps teams reason about what the data represents, what is measured, and what might be missing.\n",
    "\n",
    "We will use the same dataset across multiple modules, but we will treat it *differently* depending on the learning goal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6900cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc8dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary = pd.DataFrame({\n",
    "    \"column\": df.columns,\n",
    "    \"dtype\": [str(t) for t in df.dtypes],\n",
    "    \"example_value\": [df[c].dropna().iloc[0] if df[c].notna().any() else None for c in df.columns],\n",
    "})\n",
    "data_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d831681",
   "metadata": {},
   "source": [
    "### Notes about realism and some cheating, I mean, \"teaching affordances\"\n",
    "\n",
    "This dataset is synthetic, but it intentionally includes realistic properties that matter for modeling practice:\n",
    "\n",
    "- **Class imbalance**: fraud is rare (≈ 4% by default)\n",
    "- **High-cardinality merchant IDs**: thousands of unique merchants with a power-law distribution\n",
    "- **MNAR missingness**: missing `device_type` and sometimes `merchant_category` is *not random*\n",
    "- **Multiple targets**: a classification target (`is_fraud`) and a regression target (`transaction_loss_amount`)\n",
    "- **Optional post-event fields**: `chargeback_flag` and `manual_review_score` are present to teach **data leakage** (we will *not* use them for modeling in Module 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843e321",
   "metadata": {},
   "source": [
    "## 2) Quick profiling: distributions, missingness, and class balance\n",
    "\n",
    "**Timebox:** ~10 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3191f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "missing.to_frame(\"pct_missing\").head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19116277",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_rate = df[\"is_fraud\"].mean()\n",
    "fraud_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"transaction_amount\",\n",
    "    \"transactions_last_24h\",\n",
    "    \"transactions_last_7d\",\n",
    "    \"time_since_last_transaction_minutes\",\n",
    "    \"avg_transaction_amount_30d\",\n",
    "    \"std_transaction_amount_30d\",\n",
    "]\n",
    "df[num_cols].describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148fb383",
   "metadata": {},
   "source": [
    "## 3) Define the modeling problem for Module 1\n",
    "\n",
    "**Timebox:** ~5 minutes\n",
    "\n",
    "In Module 1, we treat this as a **static, tabular classification** problem:\n",
    "\n",
    "- **Goal:** predict `is_fraud` from available transaction context\n",
    "- **Non-goals (for now):** time series forecasting, streaming detection, delayed labels\n",
    "\n",
    "We will also explicitly avoid leakage features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"is_fraud\"\n",
    "\n",
    "LEAKAGE_COLS = [\"chargeback_flag\", \"manual_review_score\", \"fraud_probability_latent\"]\n",
    "\n",
    "# Identifiers often excluded; revisit later in the course if desired\n",
    "ID_COLS = [\"transaction_id\"]\n",
    "\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "X = df.drop(columns=[TARGET] + [c for c in LEAKAGE_COLS if c in df.columns] + [c for c in ID_COLS if c in df.columns])\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d6463",
   "metadata": {},
   "source": [
    "## 4) Train/test split (and why it matters)\n",
    "\n",
    "**Timebox:** ~5 minutes\n",
    "\n",
    "We split once, then treat the test set as **locked**. In real practice, you tune on validation data and only evaluate on the test set at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed927778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=SEED,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9933e",
   "metadata": {},
   "source": [
    "## 5) Preprocessing with pipelines (important engineering pattern)\n",
    "\n",
    "**Timebox:** ~20 minutes\n",
    "\n",
    "Key idea: **fit preprocessing only on training data**, and package preprocessing + model into a single pipeline.\n",
    "\n",
    "We will:\n",
    "- impute missing values\n",
    "- one-hot encode low-cardinality categoricals\n",
    "- handle high-cardinality categoricals carefully (Merchant IDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96608e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "numeric_features, categorical_features[:10], len(categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baecae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cardinality = [c for c in categorical_features if c in [\"merchant_id\", \"merchant_name\"]]\n",
    "low_cardinality = [c for c in categorical_features if c not in high_cardinality]\n",
    "\n",
    "high_cardinality, low_cardinality[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bba399",
   "metadata": {},
   "source": [
    "### Preprocessing strategy (Module 1 baseline)\n",
    "\n",
    "- Numeric: median imputation\n",
    "- Low-cardinality categoricals: impute missing as \"Missing\", then one-hot encode\n",
    "- High-cardinality categoricals: hash encoding (feature hashing)\n",
    "\n",
    "Feature hashing is a pragmatic way to deal with very large categorical vocabularies without exploding dimensionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bac969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnToDict(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Convert selected columns of a DataFrame into a list of dicts for FeatureHasher.\"\"\"\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        records = X[self.cols].astype(str).to_dict(orient=\"records\")\n",
    "        return records\n",
    "\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "low_cat_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "high_cat_pipe = Pipeline(steps=[\n",
    "    (\"to_dict\", ColumnToDict(high_cardinality)),\n",
    "    (\"hasher\", FeatureHasher(n_features=2**12, input_type=\"dict\")),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, numeric_features),\n",
    "        (\"low_cat\", low_cat_pipe, low_cardinality),\n",
    "        (\"high_cat\", high_cat_pipe, high_cardinality),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "preprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a7a95",
   "metadata": {},
   "source": [
    "## 6) Baseline classification model + evaluation\n",
    "\n",
    "**Timebox:** ~20 minutes\n",
    "\n",
    "We start with a (hopefully?) strong baseline:\n",
    "- Logistic Regression in a pipeline\n",
    "- Evaluate with confusion matrix + precision/recall/F1 (accuracy is not enough under imbalance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d6f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, average_precision_score\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=500)),\n",
    "])\n",
    "\n",
    "clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aae6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ef7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58fe7bd",
   "metadata": {},
   "source": [
    "### Precision–Recall and thresholds \n",
    "\n",
    "In fraud-style problems, you often choose a threshold based on operational costs.\n",
    "We’ll compute a PR curve and average precision (AP).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf.predict_proba(X_test)[:, 1]\n",
    "ap = average_precision_score(y_test, y_score)\n",
    "ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f414ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, rec, thr = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "pr_table = pd.DataFrame({\n",
    "    \"threshold\": np.r_[thr, np.nan],\n",
    "    \"precision\": prec,\n",
    "    \"recall\": rec,\n",
    "}).head(15)\n",
    "\n",
    "pr_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3106fc",
   "metadata": {},
   "source": [
    "## 7) A quick feature engineering example (we won't go too far in this mod...)\n",
    "\n",
    "**Timebox:** ~10 minutes\n",
    "\n",
    "We add one engineered feature that often matters: **log amount**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fe = X.copy()\n",
    "X_fe[\"log_transaction_amount\"] = np.log1p(X_fe[\"transaction_amount\"])\n",
    "\n",
    "X_train_fe, X_test_fe, y_train_fe, y_test_fe = train_test_split(\n",
    "    X_fe, y, test_size=0.25, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "numeric_features_fe = X_train_fe.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features_fe = X_train_fe.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "high_cardinality_fe = [c for c in categorical_features_fe if c in [\"merchant_id\", \"merchant_name\"]]\n",
    "low_cardinality_fe = [c for c in categorical_features_fe if c not in high_cardinality_fe]\n",
    "\n",
    "preprocess_fe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, numeric_features_fe),\n",
    "        (\"low_cat\", low_cat_pipe, low_cardinality_fe),\n",
    "        (\"high_cat\", Pipeline([(\"to_dict\", ColumnToDict(high_cardinality_fe)),\n",
    "                               (\"hasher\", FeatureHasher(n_features=2**12, input_type=\"dict\"))]), high_cardinality_fe),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "clf_fe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_fe),\n",
    "    (\"model\", LogisticRegression(max_iter=500)),\n",
    "])\n",
    "\n",
    "clf_fe.fit(X_train_fe, y_train_fe)\n",
    "y_score_fe = clf_fe.predict_proba(X_test_fe)[:, 1]\n",
    "\n",
    "average_precision_score(y_test_fe, y_score), average_precision_score(y_test_fe, y_score_fe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241472a5",
   "metadata": {},
   "source": [
    "## 8) Checkpoint:\n",
    "\n",
    "- Define **X vs y** correctly and avoid leakage features\n",
    "- Split data into train/test correctly (with stratification under imbalance)\n",
    "- Use **pipelines** so preprocessing is fit on training data only\n",
    "- Evaluate classification with **precision/recall/F1**, not just accuracy\n",
    "- Explain why threshold choice is a business decision\n",
    "\n",
    "### Exercises (suggested)\n",
    "- **Exercise A (guided):** reproduce the baseline pipeline + report metrics\n",
    "- **Exercise B (transfer):** try a different missingness handling strategy (e.g., “Missing” vs drop)\n",
    "- **Exercise C (diagnosis):** intentionally include a leakage column and explain what happens\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gateway uv)",
   "language": "python",
   "name": "gateway-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
