{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e478bba",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tunnel-ai/way/blob/main/notebooks/02_02_exercise_open.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a99a0",
   "metadata": {},
   "source": [
    "# Module 2 — Supervised Learning (Regression)\n",
    "## 02_02 — Constrained Decision-Making Workbook\n",
    "\n",
    "**Target:** `transaction_loss_amount`  \n",
    "**Dataset:** `generate_transaction_risk_dataset(seed=1955)` (canonical; do not modify)\n",
    "\n",
    "### Your role in this notebook\n",
    "You are not being graded on “how many models you try.” You are being graded on **two modeling decisions** you make and defend with evidence.\n",
    "\n",
    "### Hard constraints (do not change)\n",
    "1. Use the canonical generator with **seed = 1955**.\n",
    "2. Use the provided split: `test_size=0.25, random_state=1955`.\n",
    "3. Report **MAE, RMSE, and R²** on the validation set.\n",
    "4. Your final solution must use **a single sklearn `Pipeline`** named `final_model`.\n",
    "5. Include **one residual diagnostic plot** and interpret it.\n",
    "\n",
    "### What you will submit\n",
    "This notebook with:\n",
    "- a completed **Decision Log**\n",
    "- a `final_model` pipeline\n",
    "- final metrics + residual plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab-first setup (run this cell first)\n",
    "# If you're running locally, you can skip the git clone and just ensure the repo is on your PYTHONPATH.\n",
    "\n",
    "!git clone https://github.com/tunnel-ai/way.git\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/content/way/src\")\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f0c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.generators.transaction_risk_dgp import generate_transaction_risk_dataset\n",
    "\n",
    "data = generate_transaction_risk_dataset(seed=1955)\n",
    "\n",
    "# Defensive handling in case the generator returns (df, meta) or similar.\n",
    "if isinstance(data, tuple) and len(data) > 0:\n",
    "    df = data[0]\n",
    "else:\n",
    "    df = data\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8434d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity checks (do not overthink)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", len(df.columns))\n",
    "print(\"Target summary:\")\n",
    "display(df[\"transaction_loss_amount\"].describe())\n",
    "\n",
    "# Zero inflation check\n",
    "zero_rate = (df[\"transaction_loss_amount\"] == 0).mean()\n",
    "print(f\"Share of zero losses: {zero_rate:.3f}\")\n",
    "\n",
    "# A quick look at the heavy tail (non-zero only)\n",
    "nz = df.loc[df[\"transaction_loss_amount\"] > 0, \"transaction_loss_amount\"]\n",
    "print(\"Non-zero count:\", len(nz))\n",
    "if len(nz) > 0:\n",
    "    display(nz.describe(percentiles=[0.5, 0.9, 0.95, 0.99]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe0ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target and leakage exclusions (keep these explicit)\n",
    "TARGET = \"transaction_loss_amount\"\n",
    "\n",
    "# --- IMPORTANT ---\n",
    "# We are predicting loss amount per transaction. In this synthetic DGP, 'is_fraud' is strongly coupled to loss\n",
    "# and should be treated as leakage for this regression exercise (we want the model to learn signals, not the label).\n",
    "LEAKAGE_COLS = [\n",
    "    \"is_fraud\",\n",
    "]\n",
    "\n",
    "# Optional: drop identifiers that you decide are inappropriate (you will justify this if you do it).\n",
    "ID_COLS = [\n",
    "    # \"merchant_id\",   # NOTE: high-cardinality; included by default unless *you* decide otherwise (Decision Menu)\n",
    "]\n",
    "\n",
    "drop_cols = list(set(LEAKAGE_COLS + ID_COLS))\n",
    "\n",
    "y = df[TARGET].copy()\n",
    "X = df.drop(columns=[TARGET] + drop_cols).copy()\n",
    "\n",
    "# Fixed split for comparability\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=1955\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Valid:\", X_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_report(y_true, y_pred, label=\"model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"model\": label, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "def show_reports(reports):\n",
    "    out = pd.DataFrame(reports).sort_values(\"RMSE\")\n",
    "    display(out)\n",
    "    return out\n",
    "\n",
    "# Two baseline models:\n",
    "# 1) Predict 0 (important for zero-inflated targets)\n",
    "# 2) Predict the training mean (classic baseline)\n",
    "yhat_zero = np.zeros_like(y_valid, dtype=float)\n",
    "yhat_mean = np.full_like(y_valid, fill_value=float(y_train.mean()), dtype=float)\n",
    "\n",
    "reports = []\n",
    "reports.append(regression_report(y_valid, yhat_zero, label=\"baseline: predict 0\"))\n",
    "reports.append(regression_report(y_valid, yhat_mean, label=\"baseline: predict train mean\"))\n",
    "\n",
    "show_reports(reports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa95254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify column types from the training set\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = [c for c in X_train.columns if c not in numeric_features]\n",
    "\n",
    "print(\"Numeric:\", len(numeric_features))\n",
    "print(\"Categorical:\", len(categorical_features))\n",
    "print(\"Categorical columns:\", categorical_features)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54041cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter models (you will choose what to keep/improve)\n",
    "# These are NOT the goal by themselves. They give you a baseline workflow to adapt.\n",
    "\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    # Regularization with CV (kept modest to avoid huge run times)\n",
    "    \"RidgeCV\": RidgeCV(alphas=np.logspace(-3, 3, 13)),\n",
    "    \"LassoCV\": LassoCV(alphas=None, cv=5, n_jobs=None, random_state=1955, max_iter=20000),\n",
    "    \"ElasticNetCV\": ElasticNetCV(l1_ratio=[0.2, 0.5, 0.8], cv=5, random_state=1955, max_iter=20000),\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_valid)\n",
    "    reports.append(regression_report(y_valid, preds, label=name))\n",
    "\n",
    "results = show_reports(reports)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65877de4",
   "metadata": {},
   "source": [
    "## Decision Menu (choose **exactly two**)\n",
    "\n",
    "Pick **two** decisions below. For each decision:\n",
    "1. Describe *what you changed*.\n",
    "2. Explain *why* (tradeoff).\n",
    "3. Provide evidence (metrics and/or plot).\n",
    "\n",
    "### Decision A — High-cardinality `merchant_id`\n",
    "Choose one strategy (and justify):\n",
    "- A1: **Keep it** (one-hot; accept many columns)\n",
    "- A2: **Drop it** (reduce dimensionality; may lose signal)\n",
    "- A3: **Top-K one-hot + Other** (you decide K)\n",
    "- A4: **Frequency encoding** (target-agnostic; simple and compact)\n",
    "\n",
    "### Decision B — Target strategy for a zero-inflated heavy tail\n",
    "Choose one strategy (and justify):\n",
    "- B1: Model `y` directly (plain regression)\n",
    "- B2: Model `log1p(y)` and transform back with `expm1`\n",
    "- B3: Two-stage model (classify fraud → regress loss for predicted fraud), then combine\n",
    "\n",
    "### Decision C — Metric emphasis\n",
    "Pick a “primary” metric (MAE vs RMSE vs R²) and justify why it fits this context.\n",
    "\n",
    "### Decision D — Feature group inclusion\n",
    "Compare two feature sets and justify:\n",
    "- Transaction context only vs. context + customer/device\n",
    "- Or: remove suspected nuisance predictors and see what happens\n",
    "\n",
    "> **Rule:** You must implement **two** decisions. You may discuss more, but you may not build a sprawling model zoo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Decision implementation area (choose exactly two decisions) ===\n",
    "# Write your code below. Keep it readable and short.\n",
    "\n",
    "# Tip: Start by copying the best-performing model name from the table above,\n",
    "# then adapt it based on your decisions.\n",
    "\n",
    "# Example skeleton:\n",
    "# chosen_model = RidgeCV(alphas=np.logspace(-3, 3, 13))\n",
    "# model_pipe = Pipeline([(\"preprocess\", preprocess), (\"model\", chosen_model)])\n",
    "# model_pipe.fit(X_train, y_train)\n",
    "# preds = model_pipe.predict(X_valid)\n",
    "# print(regression_report(y_valid, preds, \"my_candidate\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07def66b",
   "metadata": {},
   "source": [
    "### Interpretation notes\n",
    "Write 3–6 sentences explaining your two decisions and what you expect to happen **before** you run the full evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Write your quick prediction here, then proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your final_model pipeline here\n",
    "# final_model = Pipeline([...])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual diagnostic (required)\n",
    "# Make *one* residual plot and interpret it in the markdown cell below.\n",
    "\n",
    "# Fit your chosen final model pipeline first (name it final_model).\n",
    "# Then run this cell.\n",
    "\n",
    "# --- TODO: ensure final_model exists ---\n",
    "# final_model = ...\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_valid)\n",
    "\n",
    "residuals = y_valid - y_pred\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, residuals, alpha=0.3)\n",
    "plt.axhline(0)\n",
    "plt.xlabel(\"Predicted loss amount\")\n",
    "plt.ylabel(\"Residual (actual - predicted)\")\n",
    "plt.title(\"Residuals vs Predicted\")\n",
    "plt.show()\n",
    "\n",
    "# Optional: look at absolute error vs prediction (tail sensitivity)\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, np.abs(residuals), alpha=0.3)\n",
    "plt.xlabel(\"Predicted loss amount\")\n",
    "plt.ylabel(\"Absolute error\")\n",
    "plt.title(\"Absolute Error vs Predicted\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad5645",
   "metadata": {},
   "source": [
    "## Decision Log (write-up)\n",
    "\n",
    "### Decision 1\n",
    "- **What I changed:**\n",
    "- **Why (tradeoff):**\n",
    "- **Evidence (metrics/plot):**\n",
    "\n",
    "### Decision 2\n",
    "- **What I changed:**\n",
    "- **Why (tradeoff):**\n",
    "- **Evidence (metrics/plot):**\n",
    "\n",
    "### Residual diagnosis\n",
    "What pattern do you see in the residual plot (if any)? What failure mode does it suggest (e.g., systematic underprediction for large losses, heteroskedasticity, missed nonlinearity, etc.)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "final_preds = final_model.predict(X_valid)\n",
    "final_metrics = regression_report(y_valid, final_preds, label=\"FINAL\")\n",
    "final_metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
