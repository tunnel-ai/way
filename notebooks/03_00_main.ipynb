{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aecf1b12",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tunnel-ai/way/blob/main/notebooks/03_00_main.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e8de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ada53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Course setup (uncomment and run if using Colab) --------------------------\n",
    "#!git clone https://github.com/tunnel-ai/way.git\n",
    "#import sys; sys.path.insert(0, \"/content/way/src\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad3d11",
   "metadata": {},
   "source": [
    "# Module 3 — Supervised Learning: Classification\n",
    "\n",
    "**Target:** `is_fraud` (binary classification)  \n",
    "**Canonical dataset:** `core.generators.transaction_risk_dgp.generate_transaction_risk_dataset(seed=1955)`  \n",
    "\n",
    "**Why this module matters:** fraud is **rare** and the business decision is usually about **thresholds** (who do we flag?) rather than just “accuracy”.\n",
    "\n",
    "We will:\n",
    "1. Load the canonical dataset (same generator as Modules 1–4)\n",
    "2. Establish baselines (majority class + simple heuristics)\n",
    "3. Fit a logistic regression (interpretable baseline)\n",
    "4. Fit tree-based models (nonlinear interactions)\n",
    "5. Evaluate with confusion matrix, ROC, **and Precision–Recall** (better for imbalance)\n",
    "6. Pick an operating threshold using a simple cost sketch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b292f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 1955\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef871c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load canonical dataset (do not modify generator) --------------------------\n",
    "from core.generators.transaction_risk_dgp import generate_transaction_risk_dataset\n",
    "\n",
    "df = generate_transaction_risk_dataset(seed=RANDOM_STATE)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e65351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quick EDA: class balance + target leakage reminder ------------------------\n",
    "TARGET = \"is_fraud\"\n",
    "\n",
    "fraud_rate = df[TARGET].mean()\n",
    "print(f\"Fraud rate (mean of {TARGET}): {fraud_rate:.4f}\")\n",
    "\n",
    "# IMPORTANT: transaction_loss_amount is a *post-event* outcome (0 if not fraud, >0 if fraud).\n",
    "# If we include it as a feature while predicting is_fraud, the model will \"cheat\".\n",
    "print(\"Loss > 0 rate:\", (df[\"transaction_loss_amount\"] > 0).mean())\n",
    "\n",
    "df[[TARGET, \"transaction_loss_amount\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8899d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define X/y and split (stratify for class imbalance) ----------------------\n",
    "# Drop target and any leakage columns\n",
    "X = df.drop(columns=[TARGET, \"transaction_loss_amount\"])\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train fraud rate:\", y_train.mean())\n",
    "print(\"Valid fraud rate:\", y_valid.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Identify feature types ---------------------------------------------------\n",
    "# We keep merchant_id out of the default baseline pipeline because it is high-cardinality.\n",
    "# We'll return to it later and treat it as an encoding decision.\n",
    "high_card_col = \"merchant_id\"\n",
    "\n",
    "categorical_cols = [c for c in X_train.columns if X_train[c].dtype == \"object\"]\n",
    "numeric_cols = [c for c in X_train.columns if c not in categorical_cols]\n",
    "\n",
    "# remove high-card col from categorical baseline set\n",
    "categorical_low_card = [c for c in categorical_cols if c != high_card_col]\n",
    "\n",
    "print(\"Numeric cols:\", len(numeric_cols))\n",
    "print(\"Categorical low-card cols:\", categorical_low_card)\n",
    "print(\"High-card col:\", high_card_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocessing pipeline (leakage-safe) ------------------------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess_low_card = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_low_card),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ac7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Baseline 1: majority class (DummyClassifier) ------------------------------\n",
    "dummy = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_low_card),\n",
    "    (\"model\", DummyClassifier(strategy=\"most_frequent\", random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_valid)\n",
    "\n",
    "print(\"Confusion matrix (majority-class baseline):\")\n",
    "print(confusion_matrix(y_valid, y_pred_dummy))\n",
    "print()\n",
    "print(classification_report(y_valid, y_pred_dummy, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 1: Logistic Regression (interpretable baseline) --------------------\n",
    "# class_weight='balanced' often improves recall under class imbalance.\n",
    "logit_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_low_card),\n",
    "    (\"model\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        solver=\"liblinear\",\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "logit_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit_model.predict(X_valid)\n",
    "y_proba = logit_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "print(\"Confusion matrix (logistic regression @ threshold=0.50):\")\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print()\n",
    "print(classification_report(y_valid, y_pred, digits=4))\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_proba))\n",
    "print(\"PR-AUC:\", average_precision_score(y_valid, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab06ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ROC + Precision–Recall curves --------------------------------------------\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "RocCurveDisplay.from_predictions(y_valid, y_proba)\n",
    "plt.title(\"ROC Curve — Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "PrecisionRecallDisplay.from_predictions(y_valid, y_proba)\n",
    "plt.title(\"Precision–Recall Curve — Logistic Regression\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Thresholding: choose an operating point ---------------------------------\n",
    "# Accuracy is often misleading in imbalanced problems.\n",
    "# Instead, we pick a threshold based on a (simple) cost sketch.\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, y_proba)\n",
    "\n",
    "# Drop the last precision/recall entry (has no threshold)\n",
    "precision = precision[:-1]\n",
    "recall = recall[:-1]\n",
    "\n",
    "# Example costs (edit these in class):\n",
    "# - False Negative: missed fraud (expensive)\n",
    "# - False Positive: manual review / customer friction (less expensive)\n",
    "C_FN = 50\n",
    "C_FP = 1\n",
    "\n",
    "# Compute expected cost per threshold\n",
    "# cost = C_FN * FN + C_FP * FP\n",
    "costs = []\n",
    "for t in thresholds:\n",
    "    y_hat = (y_proba >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_valid, y_hat).ravel()\n",
    "    costs.append(C_FN * fn + C_FP * fp)\n",
    "\n",
    "costs = np.array(costs)\n",
    "best_idx = costs.argmin()\n",
    "\n",
    "best_t = thresholds[best_idx]\n",
    "print(\"Best threshold (by expected cost):\", best_t)\n",
    "print(\"Min cost:\", costs[best_idx])\n",
    "\n",
    "# Show a small table around the best threshold\n",
    "window = 8\n",
    "lo = max(0, best_idx - window)\n",
    "hi = min(len(thresholds), best_idx + window + 1)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"threshold\": thresholds[lo:hi],\n",
    "    \"precision\": precision[lo:hi],\n",
    "    \"recall\": recall[lo:hi],\n",
    "    \"expected_cost\": costs[lo:hi]\n",
    "})\n",
    "summary.sort_values(\"expected_cost\").head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc56862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate logistic regression at the chosen threshold\n",
    "t = best_t\n",
    "y_hat_best = (y_proba >= t).astype(int)\n",
    "\n",
    "print(\"Confusion matrix (logistic regression @ chosen threshold):\")\n",
    "print(confusion_matrix(y_valid, y_hat_best))\n",
    "print()\n",
    "print(classification_report(y_valid, y_hat_best, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02cedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 2: Decision Tree ---------------------------------------------------\n",
    "# Trees can learn nonlinear rules and interactions but overfit easily.\n",
    "tree_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_low_card),\n",
    "    (\"model\", DecisionTreeClassifier(\n",
    "        max_depth=6,\n",
    "        min_samples_leaf=50,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_proba = tree_model.predict_proba(X_valid)[:, 1]\n",
    "tree_pred = (tree_proba >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_valid, tree_pred, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, tree_proba))\n",
    "print(\"PR-AUC:\", average_precision_score(y_valid, tree_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f962d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 3: Random Forest ---------------------------------------------------\n",
    "# Forests reduce overfitting by averaging many trees.\n",
    "rf_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_low_card),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=20,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight=\"balanced_subsample\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_proba = rf_model.predict_proba(X_valid)[:, 1]\n",
    "rf_pred = (rf_proba >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_valid, rf_pred, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, rf_proba))\n",
    "print(\"PR-AUC:\", average_precision_score(y_valid, rf_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compare models (same split, same metrics) --------------------------------\n",
    "models = {\n",
    "    \"Dummy (majority)\": dummy,\n",
    "    \"Logistic Regression\": logit_model,\n",
    "    \"Decision Tree\": tree_model,\n",
    "    \"Random Forest\": rf_model\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, model in models.items():\n",
    "    if name == \"Dummy (majority)\":\n",
    "        proba = model.predict_proba(X_valid)[:, 1] if hasattr(model.named_steps[\"model\"], \"predict_proba\") else None\n",
    "        pred = model.predict(X_valid)\n",
    "        # For dummy majority-class, proba may be constant; ROC/PR can be ill-defined in edge cases.\n",
    "        roc = roc_auc_score(y_valid, pred)\n",
    "        pr = average_precision_score(y_valid, pred)\n",
    "    else:\n",
    "        proba = model.predict_proba(X_valid)[:, 1]\n",
    "        pred = (proba >= 0.5).astype(int)\n",
    "        roc = roc_auc_score(y_valid, proba)\n",
    "        pr = average_precision_score(y_valid, proba)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_valid, pred).ravel()\n",
    "    precision_hat = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall_hat = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"precision@0.5\": precision_hat,\n",
    "        \"recall@0.5\": recall_hat,\n",
    "        \"ROC_AUC\": roc,\n",
    "        \"PR_AUC\": pr\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows).sort_values(\"PR_AUC\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c8b98",
   "metadata": {},
   "source": [
    "# Encoding decision: high-cardinality merchant_id (optional section)\n",
    "\n",
    "`merchant_id` is intentionally **high-cardinality** (Zipfian).  \n",
    "A naive one-hot encoding can explode the feature space and overfit.\n",
    "\n",
    "Here we demonstrate a simple **frequency encoding**:\n",
    "- Compute merchant frequency in the training set\n",
    "- Map merchants to that frequency (unseen merchants get a small default)\n",
    "\n",
    "This keeps the feature numeric, avoids huge sparse matrices, and forces a discussion about\n",
    "representation choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Frequency encoding for merchant_id ---------------------------------------\n",
    "X_train_fe = X_train.copy()\n",
    "X_valid_fe = X_valid.copy()\n",
    "\n",
    "merchant_freq = X_train_fe[high_card_col].value_counts(dropna=False) / len(X_train_fe)\n",
    "default_freq = merchant_freq.min()  # reasonable default for unseen merchants\n",
    "\n",
    "X_train_fe[\"merchant_id_freq\"] = X_train_fe[high_card_col].map(merchant_freq).fillna(default_freq)\n",
    "X_valid_fe[\"merchant_id_freq\"] = X_valid_fe[high_card_col].map(merchant_freq).fillna(default_freq)\n",
    "\n",
    "# Drop raw merchant_id after encoding\n",
    "X_train_fe = X_train_fe.drop(columns=[high_card_col])\n",
    "X_valid_fe = X_valid_fe.drop(columns=[high_card_col])\n",
    "\n",
    "# Recompute column sets\n",
    "categorical_cols_fe = [c for c in X_train_fe.columns if X_train_fe[c].dtype == \"object\"]\n",
    "numeric_cols_fe = [c for c in X_train_fe.columns if c not in categorical_cols_fe]\n",
    "\n",
    "preprocess_fe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols_fe),\n",
    "        (\"cat\", categorical_transformer, categorical_cols_fe),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "logit_fe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_fe),\n",
    "    (\"model\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        solver=\"liblinear\",\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "logit_fe.fit(X_train_fe, y_train)\n",
    "proba_fe = logit_fe.predict_proba(X_valid_fe)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression + merchant_id frequency encoding\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, proba_fe))\n",
    "print(\"PR-AUC:\", average_precision_score(y_valid, proba_fe))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949d697e",
   "metadata": {},
   "source": [
    "## Conceptual Notes to Self\n",
    "\n",
    "- If Random Forest improves **PR-AUC** materially over Logistic Regression, what does that imply about **nonlinear interactions** in the fraud mechanism?\n",
    "- Why is **Precision–Recall** often more informative than ROC for rare-event detection?\n",
    "- How does your **threshold choice** change the number of false positives you must operationally handle?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
