{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4869c37",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/tunnel-ai/way/blob/main/notebooks/05_00_main.ipynb\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfe4aa",
   "metadata": {},
   "source": [
    "# Module 5 — NLP: From Text to Perceived Agendas (Instructor Main)\n",
    "\n",
    "**Notebook:** `05_00_main`  \n",
    "**Cadence:** magic helpers would be good here... but I want to try and keep the live-run narrative going, so the code looks a little less tidy.\n",
    "\n",
    "**Big idea:** We will treat scientific abstracts as analytical artifacts, convert them into representations,\n",
    "and examine how different representations can create *perceptions* of differences across coarse regions.\n",
    "\n",
    "**Important:** A few notes on this... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd3366",
   "metadata": {},
   "source": [
    "## 0) Colab-first setup\n",
    "\n",
    "This notebook is designed to run in Google Colab.\n",
    "- We fetch data from the **OpenAlex** public API (no keys).\n",
    "- We cache a local CSV so you can re-run without re-fetching everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9365ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import textwrap\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a55adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you care to set a random seed (I won;t use one here)\n",
    "RNG = np.random.default_rng(1955)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output paths (adjust if your repo uses a different structure)\n",
    "DATA_DIR = \"assets/data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "RAW_CACHE_PATH = os.path.join(DATA_DIR, \"openalex_abstracts_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224510d3",
   "metadata": {},
   "source": [
    "## 1) From affiliations to regions (a necessary proxy)\n",
    "\n",
    "To explore how scientific agendas *appear* across different parts of the world, we need a way to group documents.\n",
    "For this module, we use a **coarse, affiliation-based proxy** to assign each paper to a geographic region.\n",
    "\n",
    "### What we are doing\n",
    "- We query OpenAlex for works that have abstracts and institutional affiliations.\n",
    "- We extract **institution country codes** from the metadata.\n",
    "- We assign each work to a broad region (e.g., United States, Europe, China).\n",
    "- If no clear mapping can be made, we assign **Unknown**.\n",
    "\n",
    "### What this mapping is not\n",
    "- Not author nationality\n",
    "- Not a claim about funding sources or political priorities\n",
    "- Not a unified \"national agenda\"\n",
    "- Not a clean solution for multinational collaborations\n",
    "\n",
    "Affiliation is a **proxy**, not a truth.\n",
    "\n",
    "Our question is:\n",
    "> What patterns appear when we impose structure on scientific writing and then aggregate those structures by region?\n",
    "\n",
    "Keep in mind:\n",
    "- If the mapping changes, the story may change.\n",
    "- If the representation changes, the story may change.\n",
    "- Visualization confidence is not interpretive certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9569fb0a",
   "metadata": {},
   "source": [
    "## 2) Fetch a sample of abstracts from OpenAlex (no keys)\n",
    "\n",
    "OpenAlex provides a free REST API. We'll pull a *manageable sample* of works with:\n",
    "- an abstract\n",
    "- institutional affiliation(s) with country code(s)\n",
    "\n",
    "We'll keep the sample modest to stay Colab-friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9814973",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FetchConfig:\n",
    "    per_page: int = 200\n",
    "    max_works: int = 2000          # keep Colab-friendly; increase if needed\n",
    "    from_year: int = 2022          # adjust to widen/narrow\n",
    "    concept_id: str | None = None  # optional: focus on a concept\n",
    "    mailto: str | None = None      # optional but polite: OpenAlex suggests adding a mailto\n",
    "\n",
    "CFG = FetchConfig(\n",
    "    per_page=200,\n",
    "    max_works=2000,\n",
    "    from_year=2022,\n",
    "    concept_id=None,   # if we wanted to test certain concepts: \"C154945302\" (Artificial intelligence) (maybe verify first)\n",
    "    mailto=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604bec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://api.openalex.org/works\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e06e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_openalex_url(cursor=\"*\"):\n",
    "    params = {\n",
    "        \"per-page\": CFG.per_page,\n",
    "        \"cursor\": cursor,\n",
    "        # basic filters: has abstract AND has institutions (via authorships)\n",
    "        \"filter\": f\"has_abstract:true,from_publication_date:{CFG.from_year}-01-01\",\n",
    "        # sorting by recency tends to pull clearer modern language\n",
    "        \"sort\": \"publication_date:desc\",\n",
    "    }\n",
    "    if CFG.concept_id:\n",
    "        params[\"filter\"] += f\",concept.id:{CFG.concept_id}\"\n",
    "    if CFG.mailto:\n",
    "        params[\"mailto\"] = CFG.mailto\n",
    "    return BASE, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index_to_text(inv):\n",
    "    \"\"\"\n",
    "    OpenAlex stores abstracts as an 'inverted index' (token -> list of positions).\n",
    "    We'll reconstruct an approximate text by placing tokens back at their positions.\n",
    "    This preserves word content, but not necessarily punctuation/casing.\n",
    "    \"\"\"\n",
    "    if inv is None or not isinstance(inv, dict) or len(inv) == 0:\n",
    "        return None\n",
    "    # Determine length (max position)\n",
    "    max_pos = 0\n",
    "    for token, positions in inv.items():\n",
    "        if positions:\n",
    "            max_pos = max(max_pos, max(positions))\n",
    "    tokens = [\"\"] * (max_pos + 1)\n",
    "    for token, positions in inv.items():\n",
    "        for p in positions:\n",
    "            if 0 <= p < len(tokens) and tokens[p] == \"\":\n",
    "                tokens[p] = token\n",
    "    # Fill blanks with nothing (some positions can be empty)\n",
    "    text = \" \".join([t for t in tokens if t])\n",
    "    return text if text.strip() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_country_codes(work: dict) -> list[str]:\n",
    "    \"\"\"\n",
    "    Pull country codes from institutions associated with the work's authorships.\n",
    "    We allow multiple institutions -> multiple country codes.\n",
    "    \"\"\"\n",
    "    codes = []\n",
    "    for auth in work.get(\"authorships\", []) or []:\n",
    "        for inst in auth.get(\"institutions\", []) or []:\n",
    "            cc = inst.get(\"country_code\")\n",
    "            if cc:\n",
    "                codes.append(cc.upper())\n",
    "    return sorted(set(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_openalex_sample():\n",
    "    rows = []\n",
    "    cursor = \"*\"\n",
    "    fetched = 0\n",
    "\n",
    "    while fetched < CFG.max_works:\n",
    "        url, params = build_openalex_url(cursor=cursor)\n",
    "        r = requests.get(url, params=params, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        payload = r.json()\n",
    "\n",
    "        for work in payload.get(\"results\", []) or []:\n",
    "            if fetched >= CFG.max_works:\n",
    "                break\n",
    "\n",
    "            inv = work.get(\"abstract_inverted_index\")\n",
    "            abstract = inverted_index_to_text(inv)\n",
    "            if not abstract:\n",
    "                continue\n",
    "\n",
    "            country_codes = extract_country_codes(work)\n",
    "\n",
    "            loc = work.get(\"primary_location\") or {}\n",
    "            src = loc.get(\"source\") or {}\n",
    "\n",
    "            rows.append({\n",
    "                \"openalex_id\": work.get(\"id\"),\n",
    "                \"doi\": work.get(\"doi\"),\n",
    "                \"title\": work.get(\"title\"),\n",
    "                \"publication_date\": work.get(\"publication_date\"),\n",
    "                \"primary_location\": src.get(\"display_name\"),\n",
    "                \"country_codes\": \"|\".join(country_codes) if country_codes else \"\",\n",
    "                \"n_country_codes\": len(country_codes),\n",
    "                \"abstract\": abstract,\n",
    "                \"type\": work.get(\"type\"),\n",
    "                \"cited_by_count\": work.get(\"cited_by_count\"),\n",
    "            })\n",
    "            fetched += 1\n",
    "\n",
    "        cursor = payload.get(\"meta\", {}).get(\"next_cursor\")\n",
    "        if not cursor:\n",
    "            break\n",
    "\n",
    "        # be a good API citizen\n",
    "        time.sleep(0.15)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94664fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(RAW_CACHE_PATH):\n",
    "    df = pd.read_csv(RAW_CACHE_PATH)\n",
    "    print(f\"Loaded cached sample: {len(df):,} rows from {RAW_CACHE_PATH}\")\n",
    "else:\n",
    "    df = fetch_openalex_sample()\n",
    "    print(f\"Fetched sample: {len(df):,} rows\")\n",
    "    df.to_csv(RAW_CACHE_PATH, index=False)\n",
    "    print(f\"Saved cache to {RAW_CACHE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3746c9b7",
   "metadata": {},
   "source": [
    "## 3) Quick data sanity checks\n",
    "\n",
    "Before modeling: inspect what we actually have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f2b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows:\", len(df))\n",
    "print(\"Missing abstracts:\", df[\"abstract\"].isna().sum())\n",
    "print(\"Avg abstract length (chars):\", int(df[\"abstract\"].str.len().mean()))\n",
    "print(\"Median # country codes:\", int(df[\"n_country_codes\"].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a few titles + first ~250 chars of abstracts\n",
    "for i in range(3):\n",
    "    print(\"\\n—\" * 40)\n",
    "    print(df.loc[i, \"title\"])\n",
    "    print(textwrap.shorten(df.loc[i, \"abstract\"], width=250, placeholder=\"…\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a034374",
   "metadata": {},
   "source": [
    "## 4) Region mapping (coarse, imperfect, still useful)\n",
    "\n",
    "We'll map *country codes* to broad regions:\n",
    "- **US** (United States)\n",
    "- **China**\n",
    "- **Europe** (broadly: EU + UK + EFTA + nearby; we keep it simple. I know I know Brexit... but come on.)\n",
    "- **Other**\n",
    "- **Unknown**\n",
    "\n",
    "**Note:** a paper can have multiple country codes. We'll assign:\n",
    "- If **US** appears anywhere -> label \"United States\"\n",
    "- Else if **CN** appears -> \"China\"\n",
    "- Else if any European code appears -> \"Europe\"\n",
    "- Else if any codes exist -> \"Other\"\n",
    "- Else -> \"Unknown\"\n",
    "\n",
    "This priority rule is arbitrary on purpose: it gives us a stable grouping for visualization, not truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99db7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "EUROPE_CODES = {\n",
    "    # EU members + UK + EFTA + common European countries\n",
    "    \"AT\",\"BE\",\"BG\",\"HR\",\"CY\",\"CZ\",\"DK\",\"EE\",\"FI\",\"FR\",\"DE\",\"GR\",\"HU\",\"IE\",\"IT\",\"LV\",\"LT\",\"LU\",\n",
    "    \"MT\",\"NL\",\"PL\",\"PT\",\"RO\",\"SK\",\"SI\",\"ES\",\"SE\",\n",
    "    \"GB\",\"UK\",  # UK sometimes appears as GB; UK included defensively. Brits are indecisive. \n",
    "    \"NO\",\"CH\",\"IS\",\"LI\",\n",
    "    \"UA\",\"TR\",\"RS\",\"BA\",\"ME\",\"MK\",\"AL\",\"MD\",\"BY\",\"GE\",\"AM\",\"AZ\",\n",
    "}\n",
    "\n",
    "def map_region(country_codes_str: str) -> str:\n",
    "    if not isinstance(country_codes_str, str) or country_codes_str.strip() == \"\":\n",
    "        return \"Unknown\"\n",
    "    codes = {c.strip().upper() for c in country_codes_str.split(\"|\") if c.strip()}\n",
    "    if \"US\" in codes:\n",
    "        return \"United States\"\n",
    "    if \"CN\" in codes:\n",
    "        return \"China\"\n",
    "    if len(codes & EUROPE_CODES) > 0:\n",
    "        return \"Europe\"\n",
    "    return \"Other\"\n",
    "\n",
    "df[\"region\"] = df[\"country_codes\"].apply(map_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0944e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"region\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832c9b26",
   "metadata": {},
   "source": [
    "## 5) Minimal text cleaning (decisions, not perfection)\n",
    "\n",
    "We'll keep cleaning light and transparent:\n",
    "- normalize whitespace\n",
    "- lowercase (for TF–IDF)\n",
    "- remove obvious URLs\n",
    "- remove non-letter characters *selectively* (keep hyphens and spaces)\n",
    "\n",
    "Key principle:\n",
    "> Cleaning is an argument about what information you consider irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pat = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "multi_space_pat = re.compile(r\"\\s+\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.strip()\n",
    "    s = url_pat.sub(\" \", s)\n",
    "    s = s.lower()\n",
    "    # keep letters, spaces, and hyphens; convert everything else to space\n",
    "    s = re.sub(r\"[^a-z\\s\\-]\", \" \", s)\n",
    "    s = multi_space_pat.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"text\"] = df[\"abstract\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88533eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a before/after example\n",
    "idx = 0\n",
    "print(\"TITLE:\", df.loc[idx, \"title\"])\n",
    "print(\"\\nRAW:\\n\", textwrap.shorten(df.loc[idx, \"abstract\"], width=400, placeholder=\"…\"))\n",
    "print(\"\\nCLEAN:\\n\", textwrap.shorten(df.loc[idx, \"text\"], width=400, placeholder=\"…\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b949070",
   "metadata": {},
   "source": [
    "## 6) Representation 1: TF–IDF (sparse geometry)\n",
    "\n",
    "TF–IDF is a classic baseline that is still conceptually powerful:\n",
    "- You get a high-dimensional sparse vector for each document.\n",
    "- Distance/similarity becomes a geometric question.\n",
    "\n",
    "We will keep choices explicit:\n",
    "- `min_df` / `max_df` control vocabulary inclusion.\n",
    "- `ngram_range` decides whether phrases matter.\n",
    "- stop words are a value judgment: we start with English stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1657e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    min_df=5,\n",
    "    max_df=0.9,\n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df[\"text\"])\n",
    "print(\"TF–IDF matrix shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a few top-weighted terms for one document\n",
    "doc_i = 0\n",
    "row = X[doc_i]\n",
    "if row.nnz > 0:\n",
    "    topk = 12\n",
    "    inds = row.indices[np.argsort(row.data)[-topk:][::-1]]\n",
    "    terms = [vectorizer.get_feature_names_out()[j] for j in inds]\n",
    "    weights = np.sort(row.data)[-topk:][::-1]\n",
    "    print(df.loc[doc_i, \"title\"])\n",
    "    for t, w in zip(terms, weights):\n",
    "        print(f\"{t:<28} {w:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f267c8",
   "metadata": {},
   "source": [
    "## 7) A first \"agenda lens\": similarity search\n",
    "\n",
    "We'll pick one abstract and retrieve its nearest neighbors (cosine similarity in TF–IDF space).\n",
    "This is often the *first* moment students feel \"meaning\" emerge from geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b1a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = cosine_similarity(X[0], X).ravel()\n",
    "nn = np.argsort(sim)[::-1][:10]\n",
    "\n",
    "print(\"Query document:\")\n",
    "print(\" -\", df.loc[0, \"title\"])\n",
    "print(\" - region:\", df.loc[0, \"region\"])\n",
    "print()\n",
    "\n",
    "print(\"Nearest neighbors:\")\n",
    "for j in nn[1:]:\n",
    "    print(f\"sim={sim[j]:.3f} | {df.loc[j,'region']:<13} | {textwrap.shorten(str(df.loc[j,'title']), width=80, placeholder='…')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4273a4",
   "metadata": {},
   "source": [
    "## 8) Visualizing structure: reduce dimensionality (TruncatedSVD)\n",
    "\n",
    "TF–IDF lives in a huge space. To visualize structure, we project into 2D.\n",
    "\n",
    "We'll use **TruncatedSVD** (works directly on sparse matrices).\n",
    "This is not a \"true map\" — it's a view. Views can mislead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=2, random_state=7)\n",
    "Z = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for region, sub in df.assign(x=Z[:,0], y=Z[:,1]).groupby(\"region\"):\n",
    "    plt.scatter(sub[\"x\"], sub[\"y\"], s=12, alpha=0.6, label=region)\n",
    "plt.title(\"TF–IDF → 2D projection (TruncatedSVD)\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.legend(markerscale=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c658cc",
   "metadata": {},
   "source": [
    "## 9) How stable is the \"agenda perception\"?\n",
    "\n",
    "We'll do two quick stress tests:\n",
    "\n",
    "1) Change the representation slightly (unigrams only vs unigrams+bigrams)\n",
    "2) Change vocabulary thresholds (`min_df`)\n",
    "\n",
    "The point is not optimization — it's demonstrating that stories depend on choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f588492",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_uni = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    min_df=5,\n",
    "    max_df=0.9,\n",
    "    ngram_range=(1, 1),\n",
    ")\n",
    "X_uni = vectorizer_uni.fit_transform(df[\"text\"])\n",
    "\n",
    "Z_uni = TruncatedSVD(n_components=2, random_state=7).fit_transform(X_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for region, sub in df.assign(x=Z_uni[:,0], y=Z_uni[:,1]).groupby(\"region\"):\n",
    "    plt.scatter(sub[\"x\"], sub[\"y\"], s=12, alpha=0.6, label=region)\n",
    "plt.title(\"TF–IDF (unigrams only) → 2D projection\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.legend(markerscale=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119b2aa0",
   "metadata": {},
   "source": [
    "### Reflection (live discussion)\n",
    "\n",
    "- Do the apparent separations persist?\n",
    "- Do the clouds rotate / smear / overlap?\n",
    "- If your *interpretation* changes when you tweak `ngram_range`, what does that imply?\n",
    "\n",
    "A useful conclusion is not \"regions differ.\"\n",
    "A useful conclusion is:\n",
    "> The perception of difference is sensitive to representational choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de0990",
   "metadata": {},
   "source": [
    "## 10) Optional: a lightweight \"topic lens\" (top terms by cluster)\n",
    "\n",
    "We'll do a simple KMeans clustering on the TF–IDF vectors, then interpret clusters by top terms.\n",
    "This is *not* state-of-the-art topic modeling; it's a transparent, geometry-driven baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32195853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 8\n",
    "kmeans = KMeans(n_clusters=k, random_state=7, n_init=\"auto\")\n",
    "labels = kmeans.fit_predict(X)\n",
    "\n",
    "df[\"cluster\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb873bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b93859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top terms per cluster (centroid weights)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "topn = 12\n",
    "for c in range(k):\n",
    "    top_idx = np.argsort(centroids[c])[-topn:][::-1]\n",
    "    top_terms = [terms[i] for i in top_idx]\n",
    "    print(f\"\\nCluster {c} — top terms:\")\n",
    "    print(\", \".join(top_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868e1a0e",
   "metadata": {},
   "source": [
    "### Region composition by cluster (a first aggregation)\n",
    "\n",
    "This is where \"perceived agendas\" can appear.\n",
    "Notice how quickly the table invites narrative — and how dependent it is on upstream decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(df[\"cluster\"], df[\"region\"], normalize=\"index\")\n",
    "ct.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de9709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "ct.plot(kind=\"bar\", stacked=True, figsize=(10, 5))\n",
    "plt.title(\"Cluster composition by region (row-normalized)\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Share within cluster\")\n",
    "plt.legend(title=\"Region\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37941999",
   "metadata": {},
   "source": [
    "## Wrap-up (what students should take away)\n",
    "\n",
    "- Text becomes analyzable when we choose a representation.\n",
    "- Representations create geometric structure.\n",
    "- Aggregation over that structure creates *stories*.\n",
    "- Those stories can be useful — and fragile — at the same time.\n",
    "\n",
    "In the guided exercise (`05_01`), students will replicate a subset of this pipeline and make one controlled comparison.\n",
    "In the open exercise (`05_02`), they'll choose representations and defend how (and why) their perceived patterns change."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
